<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>paulolivier.dehaye.org</title><link>http://paulolivier.dehaye.org/</link><description>Opinions are my own</description><language>en</language><lastBuildDate>Tue, 13 Jan 2015 11:43:42 GMT</lastBuildDate><generator>http://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Student privacy in the digital age</title><link>http://paulolivier.dehaye.org/posts/student-privacy-in-the-digital-age.html</link><dc:creator>Paul-Olivier Dehaye</dc:creator><description>&lt;br&gt;&lt;p&gt;Today, US President Obama is due to call for laws covering student privacy. To quote the &lt;a class="reference external" href="http://www.nytimes.com/2015/01/12/us/politics/obama-to-call-for-laws-covering-data-hacking-and-student-privacy.html"&gt;New York Times&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
The president will also propose the Student Data Privacy Act, which would prohibit technology firms from profiting from information collected in schools as teachers adopt tablets, online services and Internet-connected software, officials said.&lt;/blockquote&gt;
&lt;p&gt;This is an interesting development, very much top-down. The reality on the ground is that tech companies can do just about anything they want with student data. For instance, they can casually ditch existing regulations. Quoting the &lt;a class="reference external" href="http://chronicle.com/article/Are-MOOC-Takers-Students-/150325/"&gt;Chronicle of Higher Education&lt;/a&gt;  (December 3rd 2014):&lt;/p&gt;
&lt;blockquote&gt;
Coursera, by contrast, does not believe federal student-privacy laws apply to MOOCs, according to Vivek Goel, the company’s chief academic strategist. But the company does follow the "principles" of Ferpa when handling the data of its users, according to Mr. Goel.&lt;/blockquote&gt;
&lt;p&gt;Note that noone cares what Goel "believes": this quote only constitutes a personal commitment, he is replaceable, and indeed had left Coursera within a month of that statement. It also matters very little whether Coursera follows the principles of FERPA now. Voluntary compliance in the present, while not tapping into one of your intended revenue streams, is very different from promised regulatory compliance in the future.&lt;/p&gt;
&lt;p&gt;Obama's proposal is also bound to leave many shady areas in a field that is evolving very fast. One of the main questions would concern non-US students in MOOCs, at a time when &lt;a class="reference external" href="https://www.edsurge.com/n/2015-01-02-how-asia-is-emerging-as-the-world-s-edtech-laboratory"&gt;Asia is emerging as the World's edtech laboratory&lt;/a&gt; and &lt;a class="reference external" href="http://twitter.com/Buttarelli_G/status/443641146816729088"&gt;choices made in Europe will have a lasting impact on issues surrounding privacy&lt;/a&gt; (Buttarelli is European Data Protection Supervisor). This will fit into a larger struggle re-defining modern privacy laws, when data flows become crucial to national security.&lt;/p&gt;
&lt;p&gt;In any case, it is my belief that these issues also need bottom-up approaches. For this reason, in October 2014 I filed a &lt;a class="reference external" href="http://paulolivier.dehaye.org/posts/how-to-file-a-safe-harbor-request-for-your-personal-data.html"&gt;Safe Harbor request with Coursera&lt;/a&gt;. Safe Harbor is a program that authorises US companies to conduct business with EU based companies, provided they offer guarantees concerning data protection. This certification is a &lt;em&gt;sine qua non&lt;/em&gt; if Coursera wants to conduct business with EU-based universities. Under this program, any user has the right to request access to their data. Indeed, a couple weeks later (after sorting through several issues), Coursera did send me some of my data. However, this data was incomplete and partly inaccurate. In addition, it did not provide much light on what Coursera intends to do with this data. In reaction, back in December, I filed a second Safe Harbor request, asking many questions concerning their intentions with this data. Since Coursera still has not responded to those questions, I decided today to initiate the next step of this procedure: in accordance with &lt;a class="reference external" href="http://safeharbor.export.gov/companyinfo.aspx?id=26126"&gt;Coursera's filing at the Federal Trade Commission&lt;/a&gt;, I have contacted the recourse mechanism, i.e. the International Center for Dispute Resolution division of the American Arbitration Association.&lt;/p&gt;
&lt;p&gt;I have also notified the Data Protection Officers at the Swiss cantonal and federal levels, as well as three EU parliamentarians: Julia Reda, Marietje Schaake and Jan Albrecht.&lt;/p&gt;</description><category>coursera</category><category>privacy</category><guid>http://paulolivier.dehaye.org/posts/student-privacy-in-the-digital-age.html</guid><pubDate>Mon, 12 Jan 2015 09:59:23 GMT</pubDate></item><item><title>When Sarkozy met Coulibaly</title><link>http://paulolivier.dehaye.org/posts/when-sarkozy-met-coulibaly.html</link><dc:creator>Paul-Olivier Dehaye</dc:creator><description>&lt;br&gt;&lt;img alt="../amedy-coulibaly-and-nicolas-sarkozy.jpg" class="align-center" src="http://paulolivier.dehaye.org/amedy-coulibaly-and-nicolas-sarkozy.jpg" style="width: 512.0px; height: 356.0px;"&gt;&lt;br&gt;&lt;p&gt;The above is a picture of Nicolas Sarkozy, then French president, shaking hands with (most likely) Amedy Coulibaly, a terrorist who killed one policeman and four shoppers in a kosher supermarket in Paris early January 2015.&lt;/p&gt;
&lt;p&gt;This handshake took place on July 15 2009, at an official event at the Elysee palace, organised to promote apprenticeships for youth.&lt;/p&gt;
&lt;!-- TEASER_END: (Click to read about the sourcing of this picture and its relevance) --&gt;
&lt;p&gt;I am not 100% sure it is the same person. According to an article by &lt;a class="reference external" href="http://www.leparisien.fr/grigny-91350/amedi-27-ans-rencontre-sarkozy-cet-apres-midi-15-07-2009-580211.php"&gt;Le Parisien&lt;/a&gt;, Coulibaly was due to go on that day to the Elysee Palace. Other journalists have assessed the truth of that statement, for instance &lt;a class="reference external" href="http://www.lefigaro.fr/politique/le-scan/citations/2015/01/09/25002-20150109ARTFIG00228-en-2009-amedy-coulibaly-le-tireur-de-montrouge-etait-recu-a-l-elysee.php"&gt;Ivan Valerio for Le Figaro&lt;/a&gt; and &lt;a class="reference external" href="http://paulolivier.dehaye.org/posts/lelab.europe1.fr/Quand-Amedy-Coulibaly-suspect-presume-de-la-tuerie-de-Montrouge-etait-recu-a-l-Elysee-20124"&gt;Cyril Morin for Le Lab Europe 1&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For &lt;a class="reference external" href="http://www.bfmtv.com/societe/quand-le-parisien-s-interroge-sur-une-rencontre-entre-coulibaly-et-sarkozy-856642.html"&gt;BFMTV&lt;/a&gt;, collaborators of Sarkozy are downplaying the significance of this:&lt;/p&gt;
&lt;blockquote&gt;
L'entourage de Nicolas Sarkozy, contacté par l'AFP, a dit "ne pas pouvoir confirmer qu'il s'agit de la même personne". "Le 15 juillet 2009, au palais de l'Élysée, il a reçu des dirigeants de grandes entreprises engagées en faveur de l'emploi des jeunes et ces entreprises sont venues avec 500 jeunes en formation en alternance chez eux", a-t-on rappelé.     "A aucun moment, il n'y a eu de rencontre personnelle" entre Nicolas Sarkozy et la personne évoquée par l'article, a-t-on aussi assuré.&lt;/blockquote&gt;
&lt;p&gt;Ten months later, police searched his apartment and found 240 rounds of 7.62mm rifle ammunition.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Sourcing of the picture&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once I learned of the possible encounter, I looked for pictures of the event in press pools. The AFP had one, &lt;a class="reference external" href="http://www.imageforum-diffusion.afp.com/"&gt;here&lt;/a&gt; (search 2009-07-15 and "Sarkozy"). It was taken by Eric Feferberg.&lt;/p&gt;
&lt;p&gt;Judging from the Liberation article, other photographers were there, for instance Giancarlo Gorassini for ABACA press. Unfortunately I do not have the (journalistic) credentials to check their online archives.&lt;/p&gt;
&lt;p&gt;I sourced this picture a few days ago already, and posted it on Twitter. Since, it has started circulating, mostly on Russian websites tied to conspiracy theories, and on the &lt;a class="reference external" href="http://twitter.com/marcobreso/status/553580502444421120"&gt;Twitter account of Marco Bresolin&lt;/a&gt;. It was also shared by an Italian journalist (who picked it up 40 minutes after I did, presumably from my Twitter account), and shared onwards to at least one French far-right account.&lt;/p&gt;</description><guid>http://paulolivier.dehaye.org/posts/when-sarkozy-met-coulibaly.html</guid><pubDate>Sun, 11 Jan 2015 07:24:19 GMT</pubDate></item><item><title>Tequila, U.S. surveillance and me</title><link>http://paulolivier.dehaye.org/posts/tequila-us-surveillance-and-me.html</link><dc:creator>Paul-Olivier Dehaye</dc:creator><description>&lt;br&gt;&lt;p&gt;Do we all have something to hide? Hopefully so.&lt;/p&gt;
&lt;p&gt;My life was scheduled to change on September 12th 2001. I was supposed to move to the US, through New York, to study at Stanford for my PhD. That didn't happen, of course. The day before, as I was saying goodbyes to friends at home, we watched horrific images on television. We learned through the TV ticker tape that all transatlantic flights were grounded. I remember staying in bed for the whole week after that, sick from egoistic stress: it felt as if World War III was about to erupt, and I was moving across the world in the middle of all that. Still, in the days that followed, I tried day after day to get a seat on a plane so I could move on time for my classes. Eventually, I flew in on September 17th, still routed through New York. I remember feeling relief when we took off. When we arrived though, we circled around the long plume of smoke and I felt overwhelmed with what had actually happened. Around me, all the passengers were New York residents, sobbing as they discovered the changed landscape of their city.&lt;/p&gt;
&lt;p&gt;I flew on, and landed in California. Like everyone else, I rushed to buy a bike after realising how humongous the campus is. I remember making all the efforts to settle in: social security number, campus card, bank account, etc. Bought a phone and all the other dorm essentials. The general impression (on campus) was that the "events" were an East Coast thing, still far from the relatively peaceful West. Anyways, there was little time to reflect: it was the first week of classes, where I quickly understood how hard my first year would be leading up to my qualification exams. It was my 20th birthday that week. The older grad students had organised a party at the end of the first week, so I celebrated with them.&lt;/p&gt;
&lt;!-- TEASER_END: (Click to read the rest of this post) --&gt;
&lt;p&gt;Unfortunately, I had never drunk tequila. And even less so the el cheapo Walmart kind. After 2-3 shots, I was tired and ready to walk home, pushing my bike. I didn't make it though: on the way, in Escondido Village (the grad student residences), I collapsed. From drunkeness, sure, but also exhaustion, stress, hunger and immaturity, having never lived outside of the parental cocoon. And that's when the Stanford campus police showed up. They had been called for another party, but found me sitting there, next to my bike. They started giving me all the sobriety tests, while I was just asking for them to let me go home. Eventually they arrested me, and slapped the charge of resisting arrest on top (even though that "resistance" was only verbal, as confirmed to me later by witnesses). This allowed them to bring me to the "drunk tank", unfortunately located in San Jose, a good 50 miles away. This was actually next to the big real jail, which I got to see from the inside in the morning when I was released (presumably to impress the "nightly" residents like me, so they would not be tempted to come back for a longer stay). Waiting outside that Sunday morning was a long rank of taxicabs, each driver coming with a good dose of psychology to help reorient their clients in society. Where was I? What time is it? Etc.&lt;/p&gt;
&lt;blockquote class="epigraph"&gt;
&lt;p&gt;California: California Penal Code 647(f) considers public intoxication a misdemeanor. The code describes public intoxication as someone who displays intoxication to liquor, drugs, controlled substances or toluene and demonstrates an inability to care for themselves or others, or interferes or obstructs the free use of streets, sidewalks or other public way. California Penal Code 647(g) affords law enforcement the option to take an individual fitting the arrest criteria for 647(f), and no other crime, into civil protective custody if a "sobering facility" is available. Essentially, the detainee agrees to remain at the location until the facility's staff consents to their departure; usually after four hours and upon the belief that the detainee is safe to look after themselves. Not every municipality in California has such a facility. Also, if a person is being combative and/or is under the influence of drugs, they will be taken to jail. Unlike a person who is taken to jail, a civil detainee under 647(g) is not later prosecuted in a court of law.&lt;/p&gt;
&lt;p class="attribution"&gt;—&lt;a class="reference external" href="http://en.wikipedia.org/wiki/Public_intoxication"&gt;California code&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The more damaging consequence is that I now had a court date. It was a pretty bad situation to be in: the cops had slapped on an extra charge, so they were clearly hostile. Did they make up anything in the extended written report for the judge? I could not see it, unless I challenged the charge. I could do that by either hiring my own lawyer or committing to a public defender. The private lawyers I visited in Palo Alto all required deposits, since their goal would be to litigate for as long as I would pay. The public defender would not even talk to me or tell me how the cost would be defined unless I committed to that system. On top, it didn't really make sense to contest the charge: it is written very generically and includes "obstructing sidewalks" as an offense, a nice catchall for all kinds of mendicity, public drunkenness, etc. Me and my bike fit in there, if only for a few minutes.&lt;/p&gt;
&lt;p&gt;I called my embassy for help. They could not do anything, but from their perspective my case fit in a pattern of campus arrests over the past weeks, presumably so foreign students could be fingerprinted. I decided to plead guilty, and was promptly given a misdemeanor charge and a criminal record. This was the expected outcome, fair according to California law given the charges assigned by the campus police. The judge told me that I could wait for a year then get this expunged from my record, and to stay away from "those campus parties". For a year wherever I showed up to a party, I significantly increased the legal liability of the host (being still underaged).&lt;/p&gt;
&lt;p&gt;In the three years that followed, flying was more painful for me than the average. I learned a new word: &lt;em&gt;selectee&lt;/em&gt;. It was easy to double guess the TSA in my case: my criminal record was flagging me more often than the average foreign student from an allied country. This stopped though, around 2004. A bit later I also expunged the record, so I would not have to report it when applying for US postdocs (Harvard, for instance, has such a screening question). In the decade since, even after moving to the UK and Switzerland, I flew regularly to the U.S.&lt;/p&gt;
&lt;p&gt;In August 2012, I got a surprise at SFO though, on my way to my PhD adviser's birthday conference. Suddenly, I was assigned for additional interrogation. I had to wait for two hours before the TSA officer talked to me. That's a long time to ask yourself why. Was it random? Was it due to my arrest 11 years earlier? For two hours I just had to sit and wait.&lt;/p&gt;
&lt;p&gt;When I finally got to talk to the officer, right away he asked me questions about my arrest. I was relieved to explain my boring story, of how I got drunk one night when I turned 20. It still confuses me why this would pop up 11 years after the fact, so blatantly this time. The officer could not tell, and when asked he told me it could happen again. It's hard for me to shake this up. How badly is TSA drowning itself in big data if that really is the basis for interrogating a traveler?&lt;/p&gt;
&lt;p&gt;In any case, I am writing this now on the plane, somewhere close to Greenland. In a few hours I will land at JFK. I look forward to seeing the new Freedom tower on approach, and hope its completion can bring some sense of closure to as many people as possible.&lt;/p&gt;
&lt;p&gt;After going through JFK immigration, I will go on to Pittsburgh to a &lt;a class="reference external" href="http://www.humancomputation.com/2014/"&gt;Human Computation&lt;/a&gt; conference.&lt;/p&gt;
&lt;p&gt;(To all academics who have found out the hard way that campus police is not there to encourage free speech)&lt;/p&gt;
&lt;p&gt;(Edit, written from JFK: there was too much fog to see the new tower at landing, and probably will be on departure to Pittsburgh. However, I had the "chance" of being selected once again. This time I had to wait for an hour, and they asked me to explain why I had been arrested in "September 2001". I did, then asked if this would happen everytime. The officer said that it would, because it is directly flagged from my fingerprints. I look forward to the day of portable scanners and what not, as well as to data transfers back to Europe.)&lt;/p&gt;</description><category>privacy</category><guid>http://paulolivier.dehaye.org/posts/tequila-us-surveillance-and-me.html</guid><pubDate>Sat, 01 Nov 2014 10:53:14 GMT</pubDate></item><item><title>How to file a Safe Harbor request for your personal data</title><link>http://paulolivier.dehaye.org/posts/how-to-file-a-safe-harbor-request-for-your-personal-data.html</link><dc:creator>Paul-Olivier Dehaye</dc:creator><description>&lt;br&gt;&lt;p&gt;This is a short practical guide for Europeans and Swiss residents to file a Safe Harbor request for their personal data from a US company.&lt;/p&gt;
&lt;div class="section" id="what-is-safe-harbor"&gt;
&lt;h2&gt;What is Safe Harbor?&lt;/h2&gt;
&lt;p&gt;The &lt;a class="reference external" href="http://en.wikipedia.org/wiki/International_Safe_Harbor_Privacy_Principles"&gt;International Safe Harbor Privacy Principles&lt;/a&gt; are a set of regulations between the United States and either the European Union or Switzerland, which allow individuals based in those countries to claim back their personal data from US-based corporations.&lt;/p&gt;
&lt;p&gt;Copy-pasting from wikipedia, these principles must provide:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;&lt;strong&gt;Notice&lt;/strong&gt; - Individuals must be informed that their data is being collected and about how it will be used.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Choice&lt;/strong&gt; - Individuals must have the option to opt out of the collection and forward transfer of the data to third parties.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Onward Transfer&lt;/strong&gt; - Transfers of data to third parties may only occur to other organizations that follow adequate data protection principles.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt; - Reasonable efforts must be made to prevent loss of collected information.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Integrity&lt;/strong&gt; - Data must be relevant and reliable for the purpose it was collected for.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Access&lt;/strong&gt; - Individuals must be able to access information held about them, and correct or delete it if it is inaccurate.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enforcement&lt;/strong&gt; - There must be effective means of enforcing these rules.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;This is meant to replicate a level of privacy protection similar to that enjoyed at home. Some companies implement these rules as services that you can activate yourself (like Facebook and Twitter, for instance, although some are arguing &lt;a class="reference external" href="http://europe-v-facebook.org"&gt;Facebook is not transparent enough&lt;/a&gt;).&lt;/p&gt;
&lt;!-- TEASER_END: (Click to read how to actually apply) --&gt;
&lt;/div&gt;
&lt;div class="section" id="how-to-apply"&gt;
&lt;h2&gt;How to apply&lt;/h2&gt;
&lt;p&gt;In general, it is really easy. I will describe the process for one company, Coursera. The first step is to look at the company's Privacy Policy. If it mentions Safe Harbor (as Coursera does), then you can proceed. It might be that the privacy policy lists an email address to contact. If not, the alternative is to go to the dedicated site of the &lt;a class="reference external" href="http://www.export.gov/safeharbor/"&gt;Federal Trade Commission&lt;/a&gt;. There are two lists there, one for &lt;a class="reference external" href="https://safeharbor.export.gov/list.aspx"&gt;U.S.-E.U data exchange&lt;/a&gt;, the other is the &lt;a class="reference external" href="https://safeharbor.export.gov/swisslist.aspx"&gt;U.S.-Swiss list&lt;/a&gt;. You should then look up the relevant page. In Coursera's case , it is &lt;a class="reference external" href="http://safeharbor.export.gov/companyinfo.aspx?id=21417"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When everything goes smoothly, you should look up on that page the &lt;em&gt;Organization Contact&lt;/em&gt;. In Coursera's case, they have listed &lt;em&gt;security@coursera.org&lt;/em&gt;, which is not necessarily the best address to use. Much better seems to be &lt;em&gt;support@courserahelp.zendesk.com&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;You should then email that address with a very generic email wiht your demand. Here is an example, which you could cut and paste:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
To whom it may concern,

I would like to request a copy of all the personal data held by your company about me.
Please also describe what use you make of this data, and include a list of third parties with whom you are sharing it.

Sincerely yours,

XYZ
&lt;/pre&gt;
&lt;p&gt;Then, you should just wait for a bit.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="what-if-i-don-t-get-what-i-want"&gt;
&lt;h2&gt;What if I don't get what I want?&lt;/h2&gt;
&lt;p&gt;Your request might have different outcomes. I see a few possibilities:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;you might get everything you asked for;&lt;/li&gt;
&lt;li&gt;you might never hear back;&lt;/li&gt;
&lt;li&gt;you might get some information, but not be satisfied.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;If you want to push the matter, you can always insist and argue why you should get more of the data. Private data is meant to be understood in a very broad sense under the original EU directive, and Safe Harbor should reflect that.&lt;/p&gt;
&lt;p&gt;Still, if this doesn't work, it's important to know that you have a recourse.&lt;/p&gt;
&lt;p&gt;Safe Harbor is based on self-enforcement: the tech company informs the FTC that it complies with the principles. As part of the filing, the company has to include an option for &lt;em&gt;Dispute Resolution&lt;/em&gt;, also listed on the site of the FTC.
In Coursera's case, they list the &lt;em&gt;International Center for Dispute Resolution division of the American Arbitration Association&lt;/em&gt; as the independent recourse mechanism.&lt;/p&gt;
&lt;p&gt;At this point, you should google this arbitrator. For Coursera, you will quickly land at &lt;a class="reference external" href="http://go.adr.org/safeharbor"&gt;this site&lt;/a&gt;, which has more information, including the fact that the &lt;a class="reference external" href="http://images.go.adr.org/Web/AmericanArbitrationAssociation/%7Bfa41e5f8-52fd-407f-a380-803a4a4e1b36%7D_SafeHarbor_Fees.pdf"&gt;arbitration procedure is free (for the claimant)&lt;/a&gt;. This is not always the case, some arbitration companies require a filing fee of around $200.&lt;/p&gt;
&lt;p&gt;I have not had to go with an arbitrator yet, so I can't help you any further!&lt;/p&gt;
&lt;/div&gt;</description><category>coursera</category><category>privacy</category><guid>http://paulolivier.dehaye.org/posts/how-to-file-a-safe-harbor-request-for-your-personal-data.html</guid><pubDate>Tue, 28 Oct 2014 20:48:59 GMT</pubDate></item><item><title>Dear Daphne</title><link>http://paulolivier.dehaye.org/posts/dear-daphne.html</link><dc:creator>Paul-Olivier Dehaye</dc:creator><description>&lt;p&gt;The following is an open letter to Daphne Koller, CEO of Coursera. I sent her also a copy via email.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Dear Daphne,

Please send the email below to the students of my course "Massive Teaching: New skills required" to the entirety of my class.
As you know, I am unable to send it now that my Coursera instructor rights have been removed.

Sincerely yours,

Prof. Paul-Olivier Dehaye
University of Zurich
&lt;/pre&gt;
&lt;!-- TEASER_END: (Click to read the letter itself) --&gt;
&lt;div class="section" id="letter-to-coursera-students-of-massive-teaching-new-skills-required"&gt;
&lt;h2&gt;Letter to Coursera students of "Massive Teaching: New skills required"&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Dear students of "Massive Teaching: New skills required",&lt;/p&gt;
&lt;p&gt;I must first apologize to you for what must have been a very confusing time. It was confusing for me too.&lt;/p&gt;
&lt;p&gt;If you recall, my plan was for the course to span three weeks:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;pedagogy;&lt;/li&gt;
&lt;li&gt;technology and copyright;&lt;/li&gt;
&lt;li&gt;business models, and science-fiction of MOOCs (i.e. utopia and dystopia)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;I decided to give this course because I thought it would be important to inform widely on these topics, especially the third week. Coursera did not know what the content would be, and neither did I have the full picture: as advertised I would be responsive and adaptive to the issues arising on the forum. Coursera knew however that I would be critical then.&lt;/p&gt;
&lt;p&gt;At the end of the first week, came disputed news report of a confusing ethical lapse at Cornell University and Facebook, in conducting a study on the influence of the Facebook newsfeed on users' emotions. The main thrust of the criticism addressed towards Cornell, a university, is that it cannot shield itself from ethical responsibility by claiming the data collection has been done at Facebook, a private institution. Some Maryland law professors are now even arguing this study might actually have broken state laws on human subjects research.&lt;/p&gt;
&lt;p&gt;Since I had prepared the third week on business models, I knew right away that Coursera's partner institutions have  subjected themselves to similar criticism. It is universally acknowledged that at least for the moment, universities lose money on MOOCs. In exchange, they get recognition, brand, reach, but also crucially access to data, the raw material driving an increasingly digital economy. Universities are more and more acting like businesses, and this data is key to them. All kinds of experiments are or will be performed around this data, to improve the core business of teaching. This means that universities play dual roles here, defending simultaneously research and business. This in itself is an ethical bomb, one that weakens the standing of universities in society. In the wake of the Facebook experiment it led me to cast an even more critical eye on the handling of your data, and to judge to the best of my ability that no proper procedures were in place. In fact, I could not rule out that I myself was party of an experiment without giving any informed consent.&lt;/p&gt;
&lt;p&gt;This is the reason &lt;em&gt;why&lt;/em&gt; I pulled content: academia and civil society need to have a global debate on the issue of data mining of students, for both commercial and research purposes. Regulations differ widely across the world, and creative but morally dubious solutions are being found. However much I would have liked, my course was not the proper place to initiate that debate  since I am not qualified: the setting of a course on a commercial platform was too risky for me from a legal standpoint to even express doubts.&lt;/p&gt;
&lt;p&gt;For this reason, I resolved to pull out the videos, and simplify the forum to the maximum, to just one thread. Both my university and Coursera were surprised, and reinstated content. I welcome any further clarification by my university and Coursera on what exactly happened after I pulled content, when I was prevented from fully explaining my views to you or the public.&lt;/p&gt;
&lt;p&gt;Now that the university has clarified its position with me on the legal matters, I am glad to be able to get this message to you, via Coursera's messaging system. By definition this will have closed the first (reported) incident of censorship when teaching at Coursera.&lt;/p&gt;
&lt;p&gt;Sincerely yours,&lt;/p&gt;
&lt;p&gt;Paul-Olivier Dehaye&lt;/p&gt;
&lt;p&gt;PS: Should you not be satisfied with this account, I have written a more detailed one &lt;a class="reference external" href="http://paulolivier.dehaye.org/posts/extended-statement-on-massiveteaching-part-ii.html"&gt;here&lt;/a&gt;. You are welcome to criticize if this does not correspond to your recollection, but bear in mind the timeline. A lot of what you might have read afterwards was pure fabrication.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(EDIT November 14th: Note that this letter is destined to the 8000 or so students in my course, whom I have no way to contact otherwise. They all have very different backgrounds, which will differ substantially from your own.
As far as I know, neither institution is aiming to work any further on an alternative joint statement to these students. There are several concrete reasons to think this is problematic and needs to be addressed. Among them are issues of sensitivity towards the students, academic freedom and free speech.&lt;/p&gt;
&lt;p&gt;I do not expect this message to ever be sent as is. It is my expectation and hope however that a three-way solution can be found.)&lt;/p&gt;
&lt;/div&gt;</description><category>connected_course</category><category>coursera</category><category>massive_teaching</category><category>scholar14</category><category>t509massive</category><guid>http://paulolivier.dehaye.org/posts/dear-daphne.html</guid><pubDate>Fri, 24 Oct 2014 13:53:11 GMT</pubDate></item><item><title>Extended statement on #massiveteaching (part II)</title><link>http://paulolivier.dehaye.org/posts/extended-statement-on-massiveteaching-part-ii.html</link><dc:creator>Paul-Olivier Dehaye</dc:creator><description>&lt;p&gt;(This post is meant to be an account what happened in the Coursera course &lt;em&gt;Massive Teaching: New skills required&lt;/em&gt;. I suggest reading the &lt;a class="reference external" href="http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html"&gt;previous post&lt;/a&gt; first. This honors my commitment to trying to get the truth to my students)&lt;/p&gt;
&lt;div class="section" id="why-the-course"&gt;
&lt;h2&gt;Why the course?&lt;/h2&gt;
&lt;p&gt;I do believe that MOOCs offer many opportunities. Beyond providing educational material at a very large scale, they might for instance also help strengthen democracy or enable new discoveries. I have &lt;a class="reference external" href="http://paulolivier.dehaye.org/posts/mooc-research-proposal-using-crowdsourcing.html"&gt;submitted a grant proposal along those lines&lt;/a&gt;. Since utopian ideas often get compromised and ultimately shaped by commercial interests, I started in May 2013 to take a closer look at contracts between MOOC providers and educational institutions. Coursera was a natural choice for my focus: my university has partnered with them, they use closed source software (which increases lock-in), and they are the leading MOOC provider right now.&lt;/p&gt;
&lt;p&gt;What I read really bothered me, for a wide array of reasons. While the utopian vision of MOOCs (free-education-for-all) is compelling, these contracts reflect a very disturbing approach to that goal. In my opinion these contracts will have large societal implications, should they become the norm: disappearance of academic freedom, of the free agency of students, and complete disappearance of any form of privacy when learning. When I tried to communicate this around me, I encountered a clear lack of information on the subject. Getting past the utopian vision took time. Once there, many responded that my concerns were valid and worth discussing. In any case, this approach was ineffective: MOOC partnership decisions are often made by university administrations, based on factors other than those that drove my concerns.&lt;/p&gt;
&lt;p&gt;I decided that the best way to proceed was to teach a MOOC on the topic. The most natural place to do so was of course Coursera, and it also seemed natural to address the course to professors, i.e. individuals who might be able to affect decisions at their own institutions or in their local communities. It would also allow me to reach out to the more "typical" Coursera students and explain to them the contracts that are constructed around their learning. Finally, I thought it would be interesting to see the capacities at Coursera to reflect on their own practices.&lt;/p&gt;
&lt;p&gt;I understand the paradox of teaching on Coursera about concerns relating to teaching on Coursera, but made the calculation that the benefits outweigh the costs in this case.&lt;/p&gt;
&lt;!-- TEASER_END: (Click to read the rest of the statement) --&gt;
&lt;/div&gt;
&lt;div class="section" id="timeline-of-preparation-and-structure-of-the-course"&gt;
&lt;h2&gt;Timeline of preparation and structure of the course&lt;/h2&gt;
&lt;p&gt;The course was approved by Coursera mid-April. The Quality Assurance Protocol at Coursera requires the first two weeks of material to be uploaded ahead of the beginning of the course. The third week (and later) can be uploaded at the last minute.&lt;/p&gt;
&lt;p&gt;In consequence, I structured the course &lt;a class="reference external" href="https://www.youtube.com/watch?v=1xnBH0JDaU8"&gt;in the following way&lt;/a&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;week 1: pedagogy&lt;/li&gt;
&lt;li&gt;week 2: technology and copyright&lt;/li&gt;
&lt;li&gt;week 3: business model, science fiction (utopia/dystopia), unresolved questions&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;In other words, the first two weeks were conceived to provide background for the third week, which would be quite critical of MOOC contracts. I didn't hide from Coursera or the students that I would be critical, and used the flexibility offered by Coursera not to provide the third week material ahead of time. There were several reasons for this:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;The MOOC world changes fast. In the three weeks before the course started, two comprehensive reports came out on MOOCs. I also &lt;a class="reference external" href="http://paulolivier.dehaye.org/posts/what-i-am-doing-with-moocs-and-why-june-2nd.html"&gt;attended two conferences on MOOCs, and was co-organiser of one&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;I knew there was a risk that Coursera would shut down the course, either directly or indirectly. Coursera did drag their feet more and more in the lead up to the course. I attribute that to the realisation of the extent of what I wanted to say, but they could easily chalk it to other reasons.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;I conceived simple videos to illustrate concepts (like an illustrated glossary), but did not mean for this to constitute the whole course. The videos would be accompanied by readings and forum interactions. Of course, I recognised that students could still desire different levels of interactions, and I was fine with this diversity. Also, this course was meant to be &lt;a class="reference external" href="https://www.youtube.com/watch?v=1xnBH0JDaU8"&gt;very responsive to evolutions in the MOOC world in its later runs&lt;/a&gt;, which explains why the videos are relatively condensed and interchangeable.&lt;/p&gt;
&lt;p&gt;Because of the openness of the topic, I tried as much as possible not to give the impression of a "full course". This meant that it did not deliver either a Statement of Accomplishment or a Verified Certificate. Due to the Coursera contracts, I was still required to deliver a numerical grade at the end (which couldn't be 0% for all or 100% for all). I tentatively settled for a bland peer-feedback assessment, as I thought this would be more useful than a multiple choice quiz.&lt;/p&gt;
&lt;p&gt;In addition, I prepared some "experiments" through the course forums. The term is very confusing: these were not scientific or social experiments, but clearly advertised and explained attempts to talk with the students, get the students to engage with the content and interact with each other and advance the state-of-the-art in collaborative tools in MOOCs. Unfortunately I have now lost electronic access to the course material itself, so I cannot relay the exact wording used to explain this to the students.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="first-week-of-the-course"&gt;
&lt;h2&gt;First week of the course&lt;/h2&gt;
&lt;p&gt;The first week of the course went according to me quite well, although it was exhausting: I interacted and welcomed dozens of students on the forum, orientated them, etc.&lt;/p&gt;
&lt;p&gt;In addition, I participated with the students in the "experiments" that I had prepared:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;I had defined a process to manage the forums based on their preferences (like &lt;a class="reference external" href="http://area51.stackexchange.com/"&gt;Area 51 on Stack Exchange&lt;/a&gt;), but this had to be scrapped (lack of interest) and turned instead into a listing of desired features in forums;&lt;/li&gt;
&lt;li&gt;One student initiated a wide survey of MOOC students by MOOC students, that I encouraged;&lt;/li&gt;
&lt;li&gt;I decided to attempt to build a badging system (Open Badges is an infrastructure that allows the cryptographically secure attribution of rewards for contributions and achievements, however small or big). This was done in response to Coursera's requirement for a grade, and because I thought it would be very effective at shifting power towards the students/professors relationship rather than the universities/MOOC platforms. In my mind these badges would be based around the forums, and aim to make the final outcome more meaningful to each individual student (via student-defined badges granted through peer-feedback and certified by the instructor). This could have been achieved in this iteration or more realistically in a later iteration of the course, based on interactions already happening in the first run. In any case, this required looking a bit deeper into the kind of data collected on students (or at least the fraction of that data that was accessible to me as an instructor). To give an example, I would need to be able to see how an upvote was encoded, and whether there would be a way to retrieve useful information from that. I asked Coursera for an anonymized database dump taken &lt;em&gt;before&lt;/em&gt; the course properly started, with some forums seeded with test data (generated by me and another instructor account). When I asked to share parts of this dump with the students (even in a sanitized version with synthetic data), in the interest of transparency, it was refused. Throughout Coursera dragged their feet, which only encouraged me to dig deeper: I was also forbidden to share the supporting documentation PDFs, and my request to share those refusal emails with the students was never answered.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;During the first week, some students also started Facebook and Google Plus groups associated to the course, unprompted.&lt;/p&gt;
&lt;p&gt;From the start of the course, I also used confusion as a teaching tool, by sometimes acting a bit randomly but in non obtrusive ways. This was done to expose hidden assumptions, and incite reactions, which in a MOOC would be numerous and were likely to be contradictory and diverse. I saw this as conducive to questioning of the instructor himself (i.e. me, an individual having signed contracts unknown to the students) and therefore to exploratory learning, especially with my intended audience of professors. I realise this is quite bold, but I merely saw this as an extreme transposition to the web of the Socratic method. Since this concerned purely my teaching methods and did not involve any research component, I did not make a formal announcement about this, but was overt at the start, for instance by opening a thread with title "?". This lead one student to answer 42, then another to give an equation. Other students wrote poems.&lt;/p&gt;
&lt;p&gt;I would love to debate the value of this technique, particularly when the goal is partly to push students to turn a critical eye towards an opaque and complex legal and technical construction such as Coursera, under various restrictions on the content. Bear also in mind that students were at any point free to leave. Some certainly did but many stayed. I was also hoping that the combinatorics of the peer-feedback exercise at the end would tie loose ends at scale and cement the efficacy of the technique (since it is my suspicion that a comment such as "I am still confused by..." is more likely to elicit constructive responses from peers than "I assert this and that...").&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="second-week-of-the-course"&gt;
&lt;h2&gt;Second week of the course&lt;/h2&gt;
&lt;p&gt;Social aspects of learning are currently completely unstructured and relatively weak on MOOC platforms, so a natural next step for them is to build some form of social network for students. Whatever form it takes (decentralised around each course, for instance), it will require extensive research unlikely to be done by the university partners since it will be core to the MOOC platforms. Concerning research practices, Facebook and Coursera have very similar, open-ended, Terms of Use.&lt;/p&gt;
&lt;p&gt;During the first weekend of the course (June 29th?), the Facebook Emotion study made news: Facebook had manipulated the newsfeeds of many users, trying to selectively induce either happiness or sadness. The news coverage was extremely confusing: many academics were outraged at the lack of IRB approval, while others were unsurprised at these commercial practices.&lt;/p&gt;
&lt;p&gt;Having read Coursera Terms of Use, I knew right away that similar abuses could take place there, and had many reasons to think not enough safeguards were in place at Coursera either. I very quickly saw the &lt;a class="reference external" href="http://paulolivier.dehaye.org/posts/erosion-of-thick-legitimacy-by-coursera.html"&gt;pernicious threat that Coursera's business model and practices represent to the thick legitimacy of instructors, researchers and universities&lt;/a&gt;, and ultimately to society.&lt;/p&gt;
&lt;p&gt;Over and above this, I knew that data collected on the Coursera platform has no expiration date, can be replayed at will and that it had not been welcoming of my own transparency effort. In that sense, there was a more immediate concern, towards my students.&lt;/p&gt;
&lt;p&gt;Unlike all the material I had prepared for week 3, which was researched and based on documents available to the general public (i.e. not derived from the Quality Assurance process, the Coursera Partners' Portal or private communication), any comment of mine linking ethics of experimenting at Coursera to ethics of experimenting at Facebook would have to be speculative at the time. Making this speculation public would expose me to the risk of a legal challenge. Continuing the course would put more ethical responsibility on me since I could not be fully transparent with the students, as I had been thus far. To add to all of this, all the unresolved ethical questions led me to question the wisdom of implementing the badging experimentation within Coursera itself.&lt;/p&gt;
&lt;p&gt;I started questioning the ethics of delivering a course in those conditions. I could not escape thinking along the lines of nested Stanford Experiment (Should I promote some students to Community TA? What are the other 599 courses doing?). Whatever I could think of doing I somehow could find a darker side as well, associating it to one of the studies that I had read in preparing the course. I became confused, but at a much deeper level: under all these adverse conditions, I should probably have decided to stop the course, even if doing so exposed me to legal risk. Instead, I pressed on, and resolved to deliver the rest of the course via Twitter and Youtube instead (while the willing students would support each other through the Facebook and Google Plus groups as well). I made no decision about the third week peer-feedback exam. Of course, in doing all this, I also confused the students to this much deeper level.&lt;/p&gt;
&lt;p&gt;For somewhere between 24 and 48 hours, I improvised and set out to prepare material on Twitter to support my upcoming explanations. Some of it was also intentionally confounding, likely to be misunderstood by anyone who was not involved in the course, but easily explainable with the proper context (Coursera repeatedly ignored requests to engage with me in a more public way within the course). In my (poor) judgement, confusion could be used to expose hidden assumptions through reactions of other parties. For instance, I knew this might lead Coursera to stop the course, which was fine with me.&lt;/p&gt;
&lt;p&gt;Another "subtext" of my tweets was the risk of &lt;a class="reference external" href="http://socialmediacollective.org/2014/06/26/corrupt-personalization/"&gt;corrupt personalisation&lt;/a&gt; (June 26th) in teaching, originating from &lt;a class="reference external" href="http://blogs.law.harvard.edu/niftyc/archives/975"&gt;algorithmic culture&lt;/a&gt;. I thought it would be interesting to show this to students, centered around the World Cup taking place at the same time (Twitter, for the duration of the World Cup, offered the opportunity to do your own A/B testing by selecting which team you wanted to support).&lt;/p&gt;
&lt;p&gt;Yet another plan was to continue the course as a Twitter based game, that could involve participants external to the course as well. Setting it up as a game would allow me to imply things without properly saying them, diffusing some of the legal risk away from myself.&lt;/p&gt;
&lt;p&gt;I realise these are many options, but they did not need all to work and stick. And I knew I would be more free to explain them once the course finished.&lt;/p&gt;
&lt;p&gt;When ready, on Wednesday, I removed all content and forums, except for one forum. I also pinned one student post with an encouragement to fellow students to take ownership of their learning and join the Google Plus group associated to the course (in fact, this post is what triggered me to do this at that exact time). I removed video content because I wanted to encourage students who only watch video to consult the forums and notice that something was happening beyond business as usual. At the time I still felt very wary of the final peer-feedback exercise, and did not want these students to suddenly feel cheated. I intended to explain my actions on the very limited space I had left on the Coursera forums, at the best I could within my legal constraints.&lt;/p&gt;
&lt;p&gt;As the atmosphere had evolved between Monday and Wednesday, it was clear to me that students would be critical of switching from Coursera to another web platform. Again, this was fine as I could point them to the numerous Terms of Use I had read in preparation of the course, and show them contradictions in their own reasonings about privacy, and overreliance on sales pitches. I had already started highlighting the social network aspect of Coursera on Sunday or Monday, and ultimately wanted students to treat all those options on an equal footing, and make critical choices.&lt;/p&gt;
&lt;p&gt;Both Twitter and Youtube afford advantages that were required for me to be able to continue with the course content originally planned (hyperlinking to specific second or Tweet), while not requiring any login to consume passively.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fallout"&gt;
&lt;h2&gt;Fallout&lt;/h2&gt;
&lt;p&gt;At this stage (Wednesday), I was given a 24 hour deadline by Coursera to reinstate the content on their servers. This request arrived at 12:30 AM my time. When I woke up, I asked my university for ethical guidance through one channel.  Before I could consult with my university, by 11AM, I was removed as an instructor and Coursera engineers started reinstating content in a suspiciously selective fashion, reeking of sanctioned censorship (part of the contracts is that the instructor has to sign away rights to modify the material).&lt;/p&gt;
&lt;p&gt;Once my Coursera instructor rights were removed, in the interest of transparency, I immediately explained to the students what was going on through an etherpad document (for increased interactivity, still feeling under legal threat). Agreeing to a student request, I encouraged participants in that etherpad chat to share the document with the whole class. I also posted on the course forums and at the time I could not see that all my posts were being systematically deleted. I still do not know by whom.&lt;/p&gt;
&lt;p&gt;Confusingly, some students still received e-mail notifications of my messages, and they started to suspect I was deleting them myself. In parallel, there was increasing speculation on the blogosphere that I was performing some form of social experiment. New students were not allowed to sign up, so newcomers had little access to information about what had happened in the course itself. This fed an increased paranoia of some students against me.&lt;/p&gt;
&lt;p&gt;Despite all these misunderstandings, I was forbidden to clarify the situation with my students or the press. Later, I learned of misleading and false accusations made by Coursera to my university, and that Coursera used browsing behaviour information to support some of their claims.
I also learned that Coursera had issued legal threats against my university and was told that my own legal situation was precarious. Coursera temporarily suspended their agreement with my university. My assessment is that Coursera has so far successfully manipulated the media, my university and the students to damage my credibility and introduce doubts about my integrity.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="summary"&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;I regret the breakdown of trust that occurred during the preparation of the course between Coursera and me, since this left me with no good option when an external event (the Facebook Emotion experiment) disrupted my course plan. I think Coursera's actions after I removed the content, such as deleting my messages or misleading journalists and my university, caused undue stress to the students.&lt;/p&gt;
&lt;p&gt;I can fully understand the perspective of students who would feel cheated or manipulated in some way since so much information was hidden away from them. I tried my best to convey that a lot was going on behind the scenes (and clearly said so many times, referring explicitly to contracts and denied requests for data transparency).&lt;/p&gt;
&lt;p&gt;In the end, it feels like I have missed a chance to raise this debate and others more constructively. This is unfortunate since there are many more issues and opportunities of MOOCs I would have wanted to discuss in the third week:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;intellectual property for professors and associated labor issues (cf. &lt;a class="reference external" href="http://ucscfa.org/2013/06/scfas-ongoing-discussion-concerning-ucscs-contract-with-coursera/"&gt;UCSC Faculty union resistance to Coursera&lt;/a&gt; );&lt;/li&gt;
&lt;li&gt;reportedly bad working conditions in the Coursera Global Translator Community, and the risks of crowdsourcing more components of teaching (Community TAs or alumni-led tutoring, for instance);&lt;/li&gt;
&lt;li&gt;"partner"-walling of information in the Coursera Partner Portal that should be public (such as general best practices around MOOCs, data practices, &lt;a class="reference external" href="http://paulolivier.dehaye.org/posts/thin-legitimacy-at-whisper-facebook-and-coursera.html"&gt;discussion around IRBs&lt;/a&gt; etc);&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.youtube.com/watch?v=eJovz6IVzFU"&gt;vendor lock-in vs free/open source software&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.worklearn.org"&gt;merging of labour and educational markets, through crowdsourcing&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;technical interoperability of MOOC certificates;&lt;/li&gt;
&lt;li&gt;corrupt personalisation of educational experiences;&lt;/li&gt;
&lt;li&gt;erosion of academic freedom on commercial MOOC platforms;&lt;/li&gt;
&lt;li&gt;interactions &lt;a class="reference external" href="http://hci.uwaterloo.ca/faculty/elaw/citizenx/program.html"&gt;between MOOCs and citizen science or open democracies projects&lt;/a&gt;;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Of course, I missed a chance, but any of the other 103 Coursera partners, of which 25 or so are European or Swiss, have the option of starting a course on the same topics. I think it is very much needed: the shared interest of students and academics is to discuss these issues directly together at scale, without channeling this interaction through an intermediate corporation with obvious monetary interest. It is not clear that that many students are actually aware of any of those issues, highlighting the need for an urgent intervention on the topic.&lt;/p&gt;
&lt;p&gt;(I realise I have not answered all the questions or concerns that people might have about the course. The comment section is below, feel free to use it!)&lt;/p&gt;
&lt;/div&gt;</description><category>coursera</category><category>ethics</category><category>massive_teaching</category><category>mooc</category><category>privacy</category><guid>http://paulolivier.dehaye.org/posts/extended-statement-on-massiveteaching-part-ii.html</guid><pubDate>Mon, 20 Oct 2014 22:00:37 GMT</pubDate></item><item><title>Statement on #massiveteaching (part I)</title><link>http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html</link><dc:creator>Paul-Olivier Dehaye</dc:creator><description>&lt;p&gt;(For a more extended statement, see &lt;a class="reference external" href="http://paulolivier.dehaye.org/posts/extended-statement-on-massiveteaching-part-ii.html"&gt;here&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;My name is Paul-Olivier Dehaye, I am a mathematics professor at the University of Zurich. On June 23rd 2014, I started to teach a MOOC on Coursera, called &lt;em&gt;Teaching goes massive: New skills required&lt;/em&gt;, which was intended to last for three weeks and include a component on business practices of MOOC providers. During the course delivery, my perception of the ethical issues surrounding the course changed, which led me to alter its delivery methods. This prompted a reaction by Coursera itself, and I was censored &lt;a class="footnote-reference" href="http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html#id8" id="id1"&gt;[1]&lt;/a&gt;. In the fallout, I was also insulted and vilified online. Coursera used intentionally misleading information and deeply intrusive data held about the course and me to try to get my employer to launch a disciplinary procedure against me. Legal threats were also made.&lt;/p&gt;
&lt;p&gt;Throughout my course, I acted with the interest of the European and Swiss public in mind. The ethical concerns that led me to change the course so abruptly hinged on strong similarities between the Coursera and Facebook Terms of Use, and the lack of transparency and accountability on the data collection and "research" practices at those companies.&lt;/p&gt;
&lt;p&gt;There seems to be a very different perception across the Atlantic on privacy. As higher education moves online globally, it is important that the rest of the world does not adopt by default a Silicon Valley narrative on privacy issues in the educational domain. In my view, it is of primordial importance that European universities do not contribute to an erosion of the privacy values held by their local taxpayers &lt;a class="footnote-reference" href="http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html#id9" id="id2"&gt;[2]&lt;/a&gt;. There are fundamentally different regulatory frameworks across the Atlantic: while privacy is seen in Europe as a human rights issue, it tends to be seen in the US as a tradable commodity, akin to a property right. If we consider instead developing countries, we are currently at a juncture point on this issue: while it is no doubt beneficial to offer access to educational material for their next generation, it is questionable whether this requires exporting business practices that are under increasingly intense scrutiny at home.&lt;/p&gt;
&lt;p&gt;Privacy is only one of my concerns associated to Coursera and the current shaping of the MOOC market.&lt;/p&gt;
&lt;p&gt;By muddling the thick legitimacy of our universities with the thin legitimacy of companies backed by venture capital, we risk devaluing our core: academic freedom. This dynamic happened in other industries, such as journalism, where it has led to a complete reversal of power structures, and a struggle of journalists to remain relevant &lt;a class="footnote-reference" href="http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html#id10" id="id3"&gt;[3]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Beyond delivering educational materials worldwide, I am optimistic for the potential of MOOCs to create rich and meaningful experiences for students, through citizen science and open democracy activities for instance. There is a rapid impulse to apply similar combinations of educational and crowdsourcing techniques at a high cognitive level to the labor market &lt;a class="footnote-reference" href="http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html#id11" id="id4"&gt;[4]&lt;/a&gt;. The utopia is that this can solve labor issues on a mass scale, enabling students to extract value from their degrees right away. More ambiguously though, through &lt;em&gt;turking&lt;/em&gt; &lt;a class="footnote-reference" href="http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html#id12" id="id5"&gt;[5]&lt;/a&gt; and the privatisation of higher education certification on a large scale, this perniciously opens the door to seamless integration of these two markets into a more exploitative arrangement.&lt;/p&gt;
&lt;p&gt;Finally, we should not forget what we lose by automating any component of an educational experience. Algorithmic culture comes with its own problems (especially when those algorithms are opaque &lt;a class="footnote-reference" href="http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html#id13" id="id6"&gt;[6]&lt;/a&gt;), and big data is by definition discriminatory &lt;a class="footnote-reference" href="http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html#id14" id="id7"&gt;[7]&lt;/a&gt; and hence a threat to any attempt at fostering equality in education.&lt;/p&gt;
&lt;table class="docutils footnote" frame="void" id="id8" rules="none"&gt;&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;&lt;tbody valign="top"&gt;&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html#id1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;My profile is missing &lt;a class="reference external" href="https://www.coursera.org/zurich"&gt;from here&lt;/a&gt;, for instance.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table class="docutils footnote" frame="void" id="id9" rules="none"&gt;&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;&lt;tbody valign="top"&gt;&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html#id2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;As an example, Coursera &lt;a class="reference external" href="http://safeharbor.export.gov/companyinfo.aspx?id=21417"&gt;refuses to comply with the EU and/or Swiss Data Protection Authorities&lt;/a&gt;.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table class="docutils footnote" frame="void" id="id10" rules="none"&gt;&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;&lt;tbody valign="top"&gt;&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html#id3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;As masterfully explained by Jay Rosen, journalism professor at NYU, in &lt;a class="reference external" href="http://www.theatlantic.com/technology/archive/2014/07/facebook-has-all-the-power-you-have-almost-none/374215/"&gt;two&lt;/a&gt; &lt;a class="reference external" href="http://www.washingtonpost.com/posteverything/wp/2014/07/03/dont-blame-facebook-for-screwing-with-your-mood-blame-academia/"&gt;articles&lt;/a&gt; written in the wake of the Facebook Emotion experiment. I detail some of &lt;a class="reference external" href="http://paulolivier.dehaye.org/posts/erosion-of-thick-legitimacy-by-coursera.html"&gt;my concerns here&lt;/a&gt;.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table class="docutils footnote" frame="void" id="id11" rules="none"&gt;&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;&lt;tbody valign="top"&gt;&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html#id4"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;See the two workshops at &lt;a class="reference external" href="http://www.humancomputation.com/2014/"&gt;HCOMP 2014&lt;/a&gt; for these trends in &lt;em&gt;human computation&lt;/em&gt;.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table class="docutils footnote" frame="void" id="id12" rules="none"&gt;&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;&lt;tbody valign="top"&gt;&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html#id5"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://en.wikipedia.org/wiki/Amazon_Mechanical_Turk"&gt;"A practice that enables individuals or businesses to coordinate the use of human intelligence to perform tasks that computers are currently unable to do."&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table class="docutils footnote" frame="void" id="id13" rules="none"&gt;&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;&lt;tbody valign="top"&gt;&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html#id6"&gt;[6]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;See &lt;a class="reference external" href="http://socialmediacollective.org/2014/03/25/show-and-tell-algorithmic-culture/"&gt;Show-and-Tell: Algorithmic Culture&lt;/a&gt; and &lt;a class="reference external" href="http://socialmediacollective.org/2014/06/26/corrupt-personalization/"&gt;Corrupt Personalisation&lt;/a&gt;.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table class="docutils footnote" frame="void" id="id14" rules="none"&gt;&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;&lt;tbody valign="top"&gt;&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html#id7"&gt;[7]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;See &lt;a class="reference external" href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2477899"&gt;Big Data's Disparate Impact&lt;/a&gt;.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;</description><category>connected_course</category><category>coursera</category><category>ethics</category><category>massive_teaching</category><category>mooc</category><category>privacy</category><category>scholar14</category><category>t509massive</category><guid>http://paulolivier.dehaye.org/posts/short-statement-on-massiveteaching-part-i.html</guid><pubDate>Mon, 20 Oct 2014 21:43:30 GMT</pubDate></item><item><title>Erosion of thick legitimacy by Coursera</title><link>http://paulolivier.dehaye.org/posts/erosion-of-thick-legitimacy-by-coursera.html</link><dc:creator>Paul-Olivier Dehaye</dc:creator><description>&lt;p&gt;In my &lt;a class="reference external" href="http://paulolivier.dehaye.org/posts/thin-legitimacy-at-whisper-facebook-and-coursera.html"&gt;previous post&lt;/a&gt;, I raised the possibility that the thick legitimacy of academics would be eroded by meddling it with the thin legitimacy of Coursera (or other MOOC providers). This echoes a useful distinction that was introduced by Jay Rosen, in the wake of the Facebook Emotions experiment.&lt;/p&gt;
&lt;p&gt;Is this a theoretical risk? No, unfortunately. I can offer concrete cases tied to my Coursera MOOC &lt;em&gt;Massive Teaching: New skills required&lt;/em&gt;. These should explain why that course went South.&lt;/p&gt;
&lt;p&gt;What happened in my course is certainly complex, and this not meant to be an account of it. It discusses my reasoning about ethics, and focuses on the complexity of that interaction between thick and thin legitimacies. It ignores much of what happened when interacting with the students themselves. I finished my previous post with a video from my course outlining how different the startup and scientific processes are.&lt;/p&gt;
&lt;br&gt;&lt;center&gt;
&lt;iframe width="560" height="315" src="//www.youtube.com/embed/3SI7-oDqoFI" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;br&gt;&lt;!-- TEASER_END: (Click to read the rest of the article) --&gt;&lt;p&gt;For my own teaching, I had adopted a model that I will call &lt;em&gt;Agile Teaching&lt;/em&gt;. In fact, I explained what I meant by this in a separate video for the course:&lt;/p&gt;
&lt;br&gt;&lt;center&gt;
&lt;iframe width="560" height="315" src="//www.youtube.com/embed/1xnBH0JDaU8?list=PLtqHSxfnLCmA_E4gk-tmklKoXfEoXSly9" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;br&gt;&lt;p&gt;You can see several concepts there that reflect startup culture and the Agile methodology: failure and risks are OK, rapid iteraton, responsivity. This is similar to what Derek Bruff calls &lt;em&gt;Agile Teaching&lt;/em&gt; (&lt;a class="reference external" href="http://derekbruff.org/?page_id=1512"&gt;I think he originated the term&lt;/a&gt;). In my case, I included delivery and production as part of the concept. This actually worked very well within my course, and the technique can certainly be applied to many topics.&lt;/p&gt;
&lt;p&gt;However, since the topic was partly the business model of MOOC providers, and I was teaching so responsively, this technique is bound to hit some snags. During the preparation of the course, many interactions with the Coursera staff made me uncomfortable with their willingness to be transparent. This is bad practice but understandable, as I knew I was pushing them too fast and they were not used to that. I found other solutions, which included the a-posteriori-analysis-of-already-collected-data trick described in my previous post, for &lt;em&gt;teaching purposes&lt;/em&gt;. When, &lt;strong&gt;during the course&lt;/strong&gt;, the Facebook experiment makes the news, I went to re-read the section on education research in the Coursera Terms of Use.&lt;/p&gt;
&lt;blockquote class="epigraph"&gt;
&lt;p&gt;Records of your participation in Online Courses may be used for researching online education. In the interests of this research, you may be exposed to slight variations in the course materials that will not substantially alter your learning experience. All research findings will be reported at the aggregate level and will not expose your personal identity.&lt;/p&gt;
&lt;p class="attribution"&gt;—&lt;em&gt;Online Education Research&lt;/em&gt; in &lt;a class="reference external" href="https://www.coursera.org/about/terms"&gt;Coursera Terms of Use&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The abrupt change in the course comes from my initial misunderstanding of this passage. The first time I read it, months before the course started, I understood that it referred to research performed by my peers, with thick legitimacy. But the Facebook experiment made it clear to me that I was mistaken: this is also and primarily used to justify research/product improvement with thin legitimacy, which can be very thin indeed. Coursera is also more dangerous in that sense than Facebook, since it actively attempts to clout itself with thick legitimacy and blend the two. To give a few examples:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;there are university administrators sitting on its &lt;a class="reference external" href="https://www.coursera.org/about/leadership"&gt;University Advisory Board&lt;/a&gt;, but that power is, as far as I know, untested;&lt;/li&gt;
&lt;li&gt;they rely on AAUP membership to select US partners;&lt;/li&gt;
&lt;li&gt;they rely on Shangai rankings to select non-US partners.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Between June 29th and July 3rd, I followed the same train of thought as Jay Rosen when writing his July 3rd Washington Post article, and ultimately see three ethical dangers tied to this blending of thick and thin legitimacies:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;of abuses by academics, through the a-posteriori-analysis-of-already-collected-data trick (was what I myself did in the first week ethical? What about what I was going to do in the second week?)&lt;/li&gt;
&lt;li&gt;of abuses against the learners by Coursera, just as with the Facebook experiment (do A/B tests of teaching interventions, robots on Coursera forums and a non-transparent list of other experiments require internal ethical approval? Where is Coursera going with the right to replay student comments at will?);&lt;/li&gt;
&lt;li&gt;of abuses against professsors or their profession by Coursera (by devaluing the thicker legitimacy, the &lt;a class="reference external" href="http://paulolivier.dehaye.org/posts/moocs-journalism-and-digital-disruption.html"&gt;parallel with journalism and photography&lt;/a&gt; is strong).&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;I resolved that ultimately, in those conditions, I could not compromise my own thick legitimacy with the thinner legitimacy of Coursera. This was probably exacerbated by the topic of my course: by encouraging discussion about MOOCs in the course, and encouraging sharing of information about wishes and wants of students in the domain of MOOCs, I was in fact actively contributing to this blending of thick and thin legitimacies.&lt;/p&gt;
&lt;p&gt;My response was to pull content from the course, while not abandonning my students (by still trying to explain this on the forums, within legal limits). This action prompted a reaction from Coursera, which was to give me a deadline to reinstate the content. Once given that deadline, I attempted to raise ethical concerns within my own university (address the issue at the level of thick legitimacy) to resolve the situation. Unfortunately, through different channels the thinner legitimacy prevailed, Coursera did not respect its own deadline and I was prevented from explaining myself with my students. Ironically, pretty much at the exact same time, Rosen was putting up this on the Washington Post site:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When the study’s methods became controversial in the public square, in the press, and in online conversation, that should be a moment for the university to shine. Our strengths include: Academic freedom. Knowing what you’re talking about. “Yes, we thought of that.” To the press or to anyone else who has questions about it, we should be happy to explain our research, including ethical issues as they arise. As academics, we pride ourselves on thinking these things through. And we have procedures! If you experiment on human beings you have to follow them. Academic research is not some free-for-all. It has to meet certain standards. When those standards become controversial in the public square we are happy to explain them. Because we know what we’re doing—&lt;/p&gt;
&lt;p&gt;Except when we don’t. Reached by the Atlantic magazine, one of the academics researchers on the Facebook study chose silence rather than “let me explain our research design.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I didn't choose silence, and this was not &lt;em&gt;research&lt;/em&gt; with thick legitimacy. This was teaching with thick legitimacy. But Coursera itself is doing research with thin legitimacy, now or in the future, that I could not allow without more guarantees, that they had already refused four or five days before the Facebook experiment made the news. Possibly that stance is exaggerated, but I would welcome a discussion on this any time.&lt;/p&gt;
&lt;p&gt;In any case, when the &lt;a class="reference external" href="http://idstuff.blogspot.ch/2014/07/social-experiment-learning-experience.html"&gt;first blog post about the course came out&lt;/a&gt;, this forced silence (and PR statements issued by the thin legitimacy outfit) led to suspicion that I was myself performing experiments, violating my own thick legitimacy by not following IRB protocol. The result? The author suggests the following in the last paragraph:&lt;/p&gt;
&lt;blockquote&gt;
From a research point of view this is FASCINATING.  I would love to get a hold of the discussion forum data for both discourse and corpus linguistics analyses. On the other hand, I fear that coursera, and all involved parties, are handling this one wrong again.  We are now entering the third and final week of this MOOC on MOOCs.  Let's see how this pans out.&lt;/blockquote&gt;
&lt;p&gt;In other words, the author simultaneously complains about a situation, but wishes he could put his hands on the dataset so he could do research with thick legitimacy. He will of course never have access to that data, since Coursera owns it, from day one. Actually, there are many things that are not very inspiring about the technical architecture of the platform itself, so it might very well be that once an instructor deletes a forum, its content is unrecoverable. That's why I deleted forums when I could: to protect students, despite not having the opportunity to explain exactly why I did it (because of legal risk). Nothing has shown to me since that Coursera was able to retrieve that content.&lt;/p&gt;
&lt;p&gt;The third week of the course was supposed to contain a final, peer-feedback quiz. That quiz would be asking students generic questions about MOOCs and what they learned in the course. The same author talks about that assignment &lt;a class="reference external" href="http://idstuff.blogspot.ch/2014/07/youve-been-punkd-however-that-was.html"&gt;here&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
With regard to this "Assignment" I feel rather cynical on all fronts. On the one hand it feels like this is just another data-gathering stunt. So Paul ran his "experiment" and now he is collecting data to see what the learners say. The learners that didn't un-enroll from the course that is.  On the other hand, even if this is an earnest attempt to have learners introspect on this whole process, the attempt falls really flat on its face because this data is tainted. The questions don't address anything that happened in the course. It feels like these were written with the original learning objectives in mind, and as such it reduces this final exercise into a farce. It is a farce that does not respect the learners, and it is a farce of the educational process.&lt;/blockquote&gt;
&lt;p&gt;It's all of this, actually, and more. This was merely a draft, meant to validate the idea with Coursera staff of data-gathering in this way. But it was &lt;em&gt;also&lt;/em&gt; an earnest attempt to have learners introspect on this whole process, written with the original learning objectives in mind. I intended to tweak this draft later (maybe in a later iteration) into a more formal process, to be able to offer at scale personalised degrees that would reflect the learning that actually happened in the course. Once everything else happened, indeed the data &lt;em&gt;was&lt;/em&gt; tainted and it didn't address anything that happened in the course. The final exercise was reduced into a farce that did not respect the learners. By that time though, I was not involved anymore, and had objected multiple times to running the course and this assignment without me.&lt;/p&gt;
&lt;p&gt;After the assignment was completed by the students, that same author and some commenters on his blog &lt;a class="reference external" href="http://idstuff.blogspot.ch/2014/07/massiveteaching-experiment-falls-on.html"&gt;managed to hack into Coursera&lt;/a&gt; to get access to the data of all the students of the course. They were surprised at the diversity of responses, reflecting their own biases in understanding the complexity of the situation. On top, their interst in this data validated my own concerns: this data, beyond being useful for teaching, was valuable to research on the learner experience yet would be collected without IRB approval (it was merely used for teaching). My own thick legitimacy would enable its collection, yet I would have no option available to protect it from the eyes of Coursera, whose legitimacy is different and who might have genuine interest in that data.&lt;/p&gt;</description><category>coursera</category><category>ethics</category><category>massive_teaching</category><guid>http://paulolivier.dehaye.org/posts/erosion-of-thick-legitimacy-by-coursera.html</guid><pubDate>Mon, 20 Oct 2014 13:21:14 GMT</pubDate></item><item><title>Thin legitimacy at Whisper, Facebook and Coursera</title><link>http://paulolivier.dehaye.org/posts/thin-legitimacy-at-whisper-facebook-and-coursera.html</link><dc:creator>Paul-Olivier Dehaye</dc:creator><description>&lt;p&gt;What do tech startup companies do? We all know the theory: they build a product their users want, and then optimise it to respond to those users' wishes. The darker and more practical side, particularly when the users don't pay for the product, is that these companies need to eventually attract money somehow. In response, their product often comes wrapped with a grandiose message, a skewed description of the problems and the solutions at hand. This is an attempt to build legitimacy, to attract users. But it can only be very thin legitimacy: while no profitable avenue has been found, all roads to there are still open, and this often forces compromises on the grandiose claims. Sometimes this leads to outright lies or creative explorations of the boundary of the privacy policy or terms of use.&lt;/p&gt;
&lt;br&gt;&lt;img alt="../break.jpg" class="align-center" src="http://paulolivier.dehaye.org/break.jpg" style="width: 475.0px; height: 267.0px;"&gt;&lt;br&gt;&lt;!-- TEASER_END: (Click to read the rest of the article) --&gt;&lt;p&gt;&lt;strong&gt;Whisper&lt;/strong&gt; is a company that blew it, big time. In theory, you can use it to anonymously send electronic postcards, and to receive replies. This generates lots of sharing of very private or sensitive information. Whisper generates money by curating the content that transits through them, and forming partnerships with news organisations. While Guardian journalists were at their HQ to investigate a potential business deal, the sales pitch they received markedly differed from the pitch normally given to users: Whisper commits &lt;a class="reference external" href="http://www.theguardian.com/world/2014/oct/16/-sp-revealed-whisper-app-tracking-users"&gt;egregious and numerous violations of privacy&lt;/a&gt;, or at least of the privacy levels promised in their own Terms of Service. Journalists have thicker legitimacy in society, and indeed in this case they really &lt;em&gt;had to&lt;/em&gt; make public some of this information: some data was monitored by the US military, a clear no-no for a service used by some for whistleblowing. Judging from the pictures included in the article, the Guardian was there because it was interested in leaks of information from sensitive locations, but must have quickly determined that the legitimacy of Whisper was much too thin to actually partner with.
When this came out, the Whisper crew basically tried to accuse the journalists of grave violations of their own ethical standards (inventing characters, quotes, situations). That is not working out so well for Whisper right now.&lt;/p&gt;
&lt;p&gt;Do we need to talk about &lt;strong&gt;Facebook&lt;/strong&gt;? It has a history of eroding the public notion of privacy. While Zuckerberg now says that "Privacy is an evolving social norm", this statement hides that he very personally created this situation. He also said: "Move fast and break things. Unless you are breaking things you are not moving fast enough" and even earlier "They trust me - dumb fucks". By &lt;em&gt;intentionally&lt;/em&gt; breaking up parts of his own product repeatedly, he was able to lull the general public (or at least a significant enough portion of it) into compliance.&lt;/p&gt;
&lt;p&gt;But now Facebook goes beyond that. Around June 29th 2014, an article was published in a scientific journal describing the analysis of data collected by Facebook. Generously described, the goal was to see how the newsfeed affected the emotion of Facebook users. If happy messages are promoted, will that make you happier? Of course, since this is A/B testing, you will need to test also the converse: if sad messages are promoted, will that make you more sad? Leave the service?&lt;/p&gt;
&lt;blockquote class="epigraph"&gt;
&lt;p&gt;[W]e may use the information we receive about you[..] for internal operations, including troubleshooting, data analysis, testing, research and service improvement.&lt;/p&gt;
&lt;p class="attribution"&gt;—&lt;a class="reference external" href="http://www.forbes.com/sites/kashmirhill/2014/06/30/facebook-only-got-permission-to-do-research-on-users-after-emotion-manipulation-study/"&gt;Facebook Terms of Use&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The reactions to the publication of the experiment were very interesting:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;the public reaction was bipolar: either shocked or unimpressed;&lt;/li&gt;
&lt;li&gt;Facebook thought it was in the clear due to its Terms of Use (even though they were changed after the fact). Sheryl Sandberg, COO &lt;a class="reference external" href="http://www.huffingtonpost.com/2014/07/02/sheryl-sandberg-facebook-study_n_5551828.html"&gt;apologized&lt;/a&gt; for the &lt;em&gt;communication&lt;/em&gt; around the experiment, saying that &lt;em&gt;they never meant to upset you&lt;/em&gt;. Interesting: they never meant to upset you when telling you that they did previously mean to upset you for real. In any case, Facebook has since promised to self-regulate on the ethical front as well, for what that's worth.&lt;/li&gt;
&lt;li&gt;Cornell defended its ethical IRB: it only formally intervened after the data was collected, so it didn't have to go through IRB, or at least it was easier to let it through. This obscures the fact that the scientists involved apparently informally consulted with Facebook &lt;em&gt;before&lt;/em&gt; the data was collected.&lt;/li&gt;
&lt;li&gt;James Grimmelmann, a law professor at the University of Maryland, is &lt;a class="reference external" href="http://www.washingtonpost.com/blogs/the-switch/wp/2014/09/23/facebook-and-okcupids-psychological-studies-were-illegal-under-maryland-law-professor-argues/"&gt;arguing that what Facebook did is illegal under Maryland law&lt;/a&gt;: because it presented its study as science, Facebook may have violated State law on human subject testing.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;In other words, Facebook is now out to erode the whole scientific process in the social sciences, and in a very good position to succeed. The lure of big data access is proving irresistible to scientists, and leading them to cut corners.
Jay Rosen, an NYU journalism professor, argued on July 3rd that this was &lt;a class="reference external" href="http://www.washingtonpost.com/posteverything/wp/2014/07/03/dont-blame-facebook-for-screwing-with-your-mood-blame-academia/"&gt;toxic and corrosive to universities&lt;/a&gt;, and clearly introduced this distinction between thick and thin legitimacies.&lt;/p&gt;
&lt;!-- epigraph:

When it comes to experimenting on human beings, we should distinguish between “thick” and “thin” forms of legitimacy. Research universities — including my own institution — must be especially attentive to this distinction. Their thing is “thick” legitimacy. Anything that takes them away from it undermines the institution. [..] Thin legitimacy is when the experiments conducted on human beings are: fully legal and completely normal, as in common practice across the industry, but there is no way to know if they are minimally ethical, because companies have no duty to think such matters through or share with us their methods. --&gt;
&lt;p&gt;I think he is very correct. Both research and industry can break things, or even people (in psychology experiments). But there are operating procedures that differ in both worlds, and the ultimate burden when these legitimacies collaborate should be on the thick side, not the thin one.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Coursera&lt;/strong&gt; is very interesting in connection to the Facebook experiment: MOOCs will enable all kinds of data collection, that will lead to interesting research.&lt;/p&gt;
&lt;blockquote class="epigraph"&gt;
&lt;p&gt;Records of your participation in Online Courses may be used for researching online education. In the interests of this research, you may be exposed to slight variations in the course materials that will not substantially alter your learning experience. All research findings will be reported at the aggregate level and will not expose your personal identity.&lt;/p&gt;
&lt;p class="attribution"&gt;—&lt;em&gt;Online Education Research&lt;/em&gt; in &lt;a class="reference external" href="https://www.coursera.org/about/terms"&gt;Coursera Terms of Use&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In other words, the Coursera Terms of Use are as vague as Facebook's, with the additional muddling that legitimate research is actually also performed, with proper IRB consent. It is &lt;strong&gt;also a minefield, since thick legitimacy is here encouraging data collection and giving it away to thin legitimacy&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;When &lt;a class="reference external" href="https://tech.coursera.org/blog/2014/09/11/talks-at-coursera-a-slash-b-testing-at-internet-scale/"&gt;Coursera discusses A/B testing, they invite someone from LinkedIn&lt;/a&gt;. However grandiloquent, Coursera is the stuff of thin legitimacy. Their practices come from an industry that has spawned Google, Facebook, etc, and engineers move between those companies. At the 57:00 mark in the video, the head of analytics of Coursera shares what they themselves do. With the goal of improving the user experience, Coursera is already performing hundreds of experiments on its users. Should this be 3 pixels wide? 4? Fine. But they &lt;strong&gt;also&lt;/strong&gt; do other experiments that get much closer to uncomfortable: A/B testing on emails to see which interventions help keep users engaged with the course, for instance. This can be seen as marketing (because of the clear distinction email/Coursera forums), but will that distinction remain clear once on mobile, when these same interventions occur in-app or via push notifications? For how long will Coursera need to maintain this distinction? Is this even legal in Maryland? The Coursera employee only cites a few experiments there, but there are actually hundreds. What are the others? Are those ethically sensitive? Who makes that distinction? Is he even supposed to think of that? Did anyone approve the ethics of using robots in Coursera forums, to answer student questions?&lt;/li&gt;
&lt;li&gt;Once the data is owned by thin legitimacy, thick legitimacy has to fight to get back access to it. Coursera has a bad track record there. They make promises that they are not able or willing to keep.&lt;/li&gt;
&lt;li&gt;There is a risk that the proximity and aligned interests of academics and Coursera would lead to abuses. The history of psychology is full of these cases, where scientists forgot that they were dealing with human subjects. I suspect the a-posteriori-analysis-of-already-collected-data trick will become widespread. Did anything in &lt;a class="reference external" href="http://hapgood.us/2013/04/24/i-have-a-research-question-about-moocs-that-your-elite-institution-can-answer-in-under-an-hour/"&gt;this discussion&lt;/a&gt; already step over that line? Probably not. But this post is over a year old, and I do know that when I encouraged transparency at Coursera, three days &lt;strong&gt;before&lt;/strong&gt; the Facebook experiment came out, and explicitly mentioned that link, those issues were not understood. The post and comments between Mike Caufield, Alan Levine, Derek Bruff, Kate Bowles, Kristin Palmer and others highlight clearly how the IRB process can be gamed, and will be gamed (I am not saying or implying these posters did game it): one person with thick legitimacy collects the data via an outfit with thin legitimacy, another one with thick legitimacy analyses it. I also know that four months later I still don't hear any discussion about ethics coming from Coursera itself. I also know that Coursera has a Partner Portal, where such IRB discussions are encouraged but walled, while conveniently centralising information for Coursera itself (i.e. when they want to extend their service in one controversial direction, it will be easier to find partners with thick legitimacy who are willing to break things/people). When making the videos for my Coursera course &lt;em&gt;Massive Teaching: New skills required&lt;/em&gt;, about a month earlier, I made some of this clear, although it was still phrased purely positively:&lt;/li&gt;
&lt;/ul&gt;&lt;br&gt;&lt;center&gt;
&lt;iframe width="560" height="315" src="//www.youtube.com/embed/3SI7-oDqoFI" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;br&gt;</description><category>cogdog</category><category>coursera</category><category>derekbruff</category><category>facebook</category><category>holden</category><category>katemfd</category><category>whipser</category><guid>http://paulolivier.dehaye.org/posts/thin-legitimacy-at-whisper-facebook-and-coursera.html</guid><pubDate>Mon, 20 Oct 2014 10:30:45 GMT</pubDate></item><item><title>Networked scholars placeholder post</title><link>http://paulolivier.dehaye.org/posts/networked-scholars-placeholder-post.html</link><dc:creator>Paul-Olivier Dehaye</dc:creator><description>&lt;p&gt;This is my placeholder post for #scholar14, a &lt;a class="reference external" href="http://www.networkedscholars.net/"&gt;course for networked scholars&lt;/a&gt;.&lt;/p&gt;</description><category>scholar14</category><guid>http://paulolivier.dehaye.org/posts/networked-scholars-placeholder-post.html</guid><pubDate>Sun, 12 Oct 2014 20:20:01 GMT</pubDate></item></channel></rss>