<p>There was recently a <a class="reference external" href="https://twitter.com/AndrewBRElliott/status/507912025599934464/photo/1">picture circulating on Twitter</a>, like pictures do.</p>
<img alt="../why_google.jpg" class="align-center" src="../why_google.jpg" style="width: 370.8px; height: 338.4px;" />
<br><p>This is, to say the least, a skewed view of academia, although I am certainly not the best placed to say that. I tend to have a beard, use big words, have recently started blogging and did <a class="reference external" href="http://en.wikipedia.org/wiki/Academic_dress_of_the_University_of_Oxford">wear robes at some point in my academic career</a>. This is however a good opportunity to show how algorithmic bias works.</p>
<p>First off, where does the bias originate here?
As I explained before in my post on <a class="reference external" href="../posts/social-teaching-machines.html">social teaching machines</a>, autocompletion surfaces information collected previously. The information in this case is collected in various ways, most notably by looking at previous searches. It is difficult to make broad statements on why people make a Google search. It's an act that always occurs in a certain context, a ton of different reasons, and Google optimises for an average that is unclear. Who else is making the same search will undoubtedly have an effect on how it sees the context of a search. Indeed, consider the <a class="reference external" href="https://www.google.ch/?gfe_rd=cr&amp;ei=uvERVIGPKKbC8gfCuIGQAg&amp;gws_rd=ssl#q=why+do+english+people+have+british+humor">search</a> <em>Why do English people have British humor?</em> That search feels a bit odd, but the first answer suggests that indeed lots of Americans are bound to wonder about that.</p>
<br><img alt="../british_humor.jpg" class="align-center" src="../british_humor.jpg" style="width: 546.4px; height: 196.8px;" />
<br><p>I am a bit at a loss to say more on this, so feel free to comment.</p>
<p>In any cases, some of those biases are substantially more serious, of course. For this, you simply have to enter a search of the form &quot;Why do <strong>A</strong> people <strong>B</strong>&quot;, where <strong>A</strong> can be any of {<em>asian</em>, <em>white</em>, <em>black</em>} and <strong>B</strong> any of {<em>look</em>, <em>like</em> <em>smell</em>} to realise that autocomplete is powerful to surface common stereotypes. Not all those autocompletes work though (presumably because the output is too vile and has been hand blocked). So we humans enter our biases, and Google actually amplifies them.</p>
<p>Let's see where this leads.</p>
<p>In the case of autocompletion, the impact is certainly weak, but it might correlate with other biases (or cause them?), underscoring a more ingrained problem. Let's go back to Google's view of academia: what does the output of a Google Image Search of <em>academics faculty</em> return?  You can try to use this <a class="reference external" href="https://www.google.com/search?site=&amp;tbm=isch&amp;source=hp&amp;biw=1366&amp;bih=635&amp;q=academics+faculty&amp;oq=academics+faculty">link</a>, which is user agnostic (but its output will be personalized by Google once you click, unless you use privacy conscious tools). Here is the view I get, when logged in:</p>
<img alt="../why_google_images.jpg" class="align-center" src="../why_google_images.jpg" style="width: 1340.0px; height: 611.0px;" />
<br><p>Yours should be different: most probably, Terence Tao, the short-sleeved mathematician in the middle row is further down in yours. This is reasonable, and explained by <a class="reference external" href="http://www-personal.umich.edu/~csandvig/">Christian Sandvig</a> in a beautiful post called <a class="reference external" href="http://socialmediacollective.org/2014/03/25/show-and-tell-algorithmic-culture/">Show-and-Tell: Algorithmic Culture</a>: since I am a mathematician, Google gives Tao a bump <a class="footnote-reference" href="#id2" id="id1">[1]</a>. And beyond that? Well, Google <em>really</em> thinks that academics wear robes half the time, and perpetuates this bias also visually, not just in autocomplete. One consequence is that when humans need to illustrate something (a blog, an educational resource,...) it actually requires effort, judgement not to succumb to that bias. For robes it is of course very easy. For skin color or diversity, as we know, it can be harder and thus requires training and conscious effort, since what you see out of Google is <em>potentially</em> already biased. I say here <em>potentially</em>, since no one exterior to Google knows (or even most likely no one inside Google has a full understanding of the algorithms used).</p>
<p>Services like <a class="reference external" href="http://www.ece.nus.edu.sg/stfpage/eletp/Projects/Sketch2Photo/">Sketch2Photo</a></p>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>This effect, of showing me Tao higher than average, might be reasonable in this case, but it could also lead to some form of <a class="reference external" href="http://en.wikipedia.org/wiki/Filter_bubble">filter bubble</a> if there were (many) more mathematicians, and other unforeseen consequences as tested by the <a class="reference external" href="http://www.forbes.com/sites/dailymuse/2014/08/04/the-facebook-experiment-what-it-means-for-you/">recent Facebook experiment</a>.</td></tr>
</tbody>
</table>
