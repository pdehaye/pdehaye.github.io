<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>paulolivier.dehaye.org (google)</title><link>http://paulolivier.dehaye.org/</link><description></description><language>en</language><lastBuildDate>Tue, 09 Dec 2014 09:55:02 GMT</lastBuildDate><generator>http://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>The academic (social) machine (part I)</title><link>http://paulolivier.dehaye.org/posts/the-academic-social-machine-part-I.html</link><dc:creator>Paul-Olivier Dehaye</dc:creator><description>&lt;p&gt;There was recently a &lt;a class="reference external" href="https://twitter.com/AndrewBRElliott/status/507912025599934464/photo/1"&gt;picture circulating on Twitter&lt;/a&gt;, like pictures do.&lt;/p&gt;
&lt;img alt="../why_google.jpg" class="align-center" src="http://paulolivier.dehaye.org/why_google.jpg" style="width: 370.8px; height: 338.4px;"&gt;&lt;br&gt;&lt;p&gt;This is, to say the least, a skewed view of academia, although I am certainly not the best placed to say that. I tend to have a beard, use big words, have recently started blogging and did &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Academic_dress_of_the_University_of_Oxford"&gt;wear robes at some point in my academic career&lt;/a&gt;. This is however a good opportunity to show how algorithmic bias works.&lt;/p&gt;
&lt;p&gt;First off, where does the bias originate here?
As I explained before in my post on &lt;a class="reference external" href="http://paulolivier.dehaye.org/posts/social-teaching-machines.html"&gt;social teaching machines&lt;/a&gt;, autocompletion surfaces information collected previously. The information in this case is collected in various ways, most notably by looking at previous searches. It is difficult to make broad statements on why people make a Google search. It's an act that always occurs in a certain context, for a ton of different reasons, and Google optimises for an average that is unclear. Who else is making the same search will undoubtedly have an effect on how Google sees the context of a search. Consider the &lt;a class="reference external" href="https://www.google.ch/?gfe_rd=cr&amp;amp;ei=uvERVIGPKKbC8gfCuIGQAg&amp;amp;gws_rd=ssl#q=why+do+english+people+have+british+humor"&gt;search&lt;/a&gt; &lt;em&gt;Why do English people have British humor?&lt;/em&gt; and its first answer: Google obviously got the context wrong in my case.&lt;/p&gt;
&lt;br&gt;&lt;img alt="../british_humor.jpg" class="align-center" src="http://paulolivier.dehaye.org/british_humor.jpg" style="width: 546.4px; height: 196.8px;"&gt;&lt;br&gt;&lt;p&gt;I am a bit at a loss to say more on this, so feel free to comment.&lt;/p&gt;
&lt;p&gt;In any case, some of those biases are substantially more serious, of course. For this, you simply have to enter a search of the form "Why do &lt;strong&gt;A&lt;/strong&gt; people &lt;strong&gt;B&lt;/strong&gt;", where &lt;strong&gt;A&lt;/strong&gt; can be any of {&lt;em&gt;asian&lt;/em&gt;, &lt;em&gt;white&lt;/em&gt;, &lt;em&gt;black&lt;/em&gt;} and &lt;strong&gt;B&lt;/strong&gt; any of {&lt;em&gt;look&lt;/em&gt;, &lt;em&gt;like&lt;/em&gt; &lt;em&gt;smell&lt;/em&gt;} to realise that autocomplete is powerful to surface common stereotypes. Not all those autocompletes work though (presumably because the output is too vile and has been hand blocked). So we humans enter our biases, and Google actually amplifies them.&lt;/p&gt;
&lt;p&gt;Let's see where this leads.&lt;/p&gt;
&lt;p&gt;In the case of autocompletion, the impact is certainly weak, but it might correlate with other biases (or cause them?), underscoring a more ingrained problem. Let's go back to Google's view of academia: what does the output of a Google Image Search of &lt;em&gt;academics faculty&lt;/em&gt; return?  You can try to use this &lt;a class="reference external" href="https://www.google.com/search?site=&amp;amp;tbm=isch&amp;amp;source=hp&amp;amp;biw=1366&amp;amp;bih=635&amp;amp;q=academics+faculty&amp;amp;oq=academics+faculty"&gt;link&lt;/a&gt;, which is user agnostic (but its output will be personalized by Google once you click, unless you use privacy conscious tools). Here is the view I get, when logged in:&lt;/p&gt;
&lt;img alt="../why_google_images.jpg" class="align-center" src="http://paulolivier.dehaye.org/why_google_images.jpg" style="width: 1340.0px; height: 611.0px;"&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;Yours should be different: most probably, &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Terence_Tao"&gt;Terence Tao&lt;/a&gt;, the short-sleeved mathematician in the middle row, is further down in yours. This is reasonable, and explained by &lt;a class="reference external" href="http://www-personal.umich.edu/~csandvig/"&gt;Christian Sandvig&lt;/a&gt; in a beautiful post called &lt;a class="reference external" href="http://socialmediacollective.org/2014/03/25/show-and-tell-algorithmic-culture/"&gt;Show-and-Tell: Algorithmic Culture&lt;/a&gt;: since I am a mathematician, Google gives Tao a bump &lt;a class="footnote-reference" href="http://paulolivier.dehaye.org/posts/the-academic-social-machine-part-I.html#id2" id="id1"&gt;[1]&lt;/a&gt;. And beyond that? Well, Google &lt;em&gt;really&lt;/em&gt; thinks that academics wear robes half the time, and perpetuates this bias also visually, not just in autocomplete.&lt;/p&gt;
&lt;p&gt;Is this really a serious problem? Well, one consequence is that when humans need to illustrate something (a blog, an educational resource,...) it actually requires effort, judgement to accurately assess the potential bias and not succumb to it. For robes it is of course very easy. For skin color or diversity, as we know, it can be harder and thus requires training and conscious effort. In its outputs, Google is &lt;em&gt;potentially&lt;/em&gt; already biased, in ways that are hard to assess for all of us who don't know the Google secret sauce.&lt;/p&gt;
&lt;p&gt;Automation is moving rapidly in many areas. Online advertising could easily remove any intermediate human step, refeeding to us our own biases for commercial gain. Services like &lt;a class="reference external" href="http://www.ece.nus.edu.sg/stfpage/eletp/Projects/Sketch2Photo/"&gt;Sketch2Photo&lt;/a&gt; offer the promise of automating the illustration processes, for instance for lecture notes, which would perpetuate this same effect over more vulnerable populations.&lt;/p&gt;
&lt;table class="docutils footnote" frame="void" id="id2" rules="none"&gt;&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;&lt;tbody valign="top"&gt;&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="http://paulolivier.dehaye.org/posts/the-academic-social-machine-part-I.html#id1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;The fact that Tao is bumped higher than average for me is probably good. It makes the output more relevant to me. If overdone it could also lead to some form of &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Filter_bubble"&gt;filter bubble&lt;/a&gt;.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;</description><category>algorithmic_bias</category><category>google</category><category>social_machine</category><guid>http://paulolivier.dehaye.org/posts/the-academic-social-machine-part-I.html</guid><pubDate>Thu, 11 Sep 2014 11:40:33 GMT</pubDate></item><item><title>Edtech policies (part I)</title><link>http://paulolivier.dehaye.org/posts/edtech-policies-part-i.html</link><dc:creator>Paul-Olivier Dehaye</dc:creator><description>&lt;p&gt;In a previous post, I talked about some of the problems associated with &lt;a class="reference external" href="http://paulolivier.dehaye.org/posts/dont-be-evil-or-how-i-learned-to-behave-like-a-startup-and-love-the-data.html"&gt;data collection with no clear purpose&lt;/a&gt;. In this one, I want to compare two of the big players in edtech on a narrow point, that of comment posts and their associated privacy. This is partly done in response to &lt;a class="reference external" href="https://twitter.com/funnymonkey"&gt;Bill Fitzgerald&lt;/a&gt;'s posts on edtech privacy policies, but also as a concerned parent looking a bit far out in the future.&lt;/p&gt;
&lt;p&gt;On June 26th Google held an I/O developer conference. I was hoping, like many, some kind of announcement about &lt;a class="reference external" href="http://www.mooc.org"&gt;mooc.org&lt;/a&gt;. Not much was said on that, but it was still an instructive watch of the efforts of Google in the MOOC space. I was particularly struck by a comment of Julia Wilkowski (leader in their MOOC project) following a question from the audience. The comment is at 28:35, if it does not play for you:&lt;/p&gt;
&lt;embed&gt;&lt;iframe width="640" height="360" src="//www.youtube.com/embed/YCUZ01yFtsM" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/embed&gt;&lt;p&gt;She informs us that no sophisticated analysis has been performed thus far on the Google MOOC forum posts. There are apparently two reasons: it is complicated, and they are required to delete all the posts after 60 days to comply with their privacy policy. Indeed, Google MOOCs fall under the global umbrella of the Google Privacy Policy, which seems to uniformly apply to all their products. The main reason for this number seems to be technical rather than anything else (the backup system is presumably very complex, extending all the way to physical tapes), since I couldn't find a reference to it in the Google Privacy Policy (and neither could other people, if you, well, google it).&lt;/p&gt;
&lt;p&gt;A tad later, Peter Norvig talks about classifiers (similar to those used in the recent Facebook experiment that would make the news 3 or 4 days later), for instance to help determine when a student might be confused, a classic trick in intelligent tutoring systems. He immediately reminds us though:&lt;/p&gt;
&lt;blockquote class="epigraph"&gt;
&lt;p&gt;But there still are a lot of privacy issues involved in what [..] information can you keep, how much can you tie the identity in the forum to the identity of the student, can you tie that to their identity someplace else, and the field as a whole has to come to grips with the privacy issues so we can share and learn what we want without violating privacy.&lt;/p&gt;
&lt;p class="attribution"&gt;—Peter Norvig&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Coursera is another big player in the market, with a rather different approach. In their Terms of Service and Privacy policy, one can find the following:&lt;/p&gt;
&lt;img alt="../forum-reuse.jpg" class="align-center" src="http://paulolivier.dehaye.org/forum-reuse.jpg" style="width: 868.0px; height: 112.0px;"&gt;&lt;p&gt;The most remarkable sentence here is: &lt;strong&gt;We also reserve the right to reuse Forum posts containing Personally Identifiable Information in future versions of the course we offer, and to enhance further course offerings.&lt;/strong&gt; This sentence is very puzzling to me. What does it mean? The only logical explanation I can offer is that Coursera plans to repopulate forums in later iterations of the course with posts from a previous run, presumably one where there was more emphasis on moderating the course. Ask a dumb question once, and it will be asked again on repeat, &lt;strong&gt;in your name&lt;/strong&gt;, in contexts you don't necessarily know. Share a bit too much of your great idea for a startup, in a context where you feel confortable, well, too bad: it might be reshared again, even if you delete your post at the end of a course (many MOOC students have the feeble illusion that this protects their intellectual property).&lt;/p&gt;
&lt;p&gt;The Terms of Service also include the following, which is classically &lt;a class="reference external" href="https://www.google.ch/webhp?sourceid=chrome-instant&amp;amp;ion=1&amp;amp;espv=2&amp;amp;ie=UTF-8#q=%22Neither+the+User+Content+(as+defined+below)+on+these+Sites%2C+nor+any+links+to+other+websites%2C+are+screened%2C+moderated%2C+approved%2C+reviewed+or+endorsed%22&amp;amp;start=0"&gt;present in many platform disclaimers&lt;/a&gt;:&lt;/p&gt;
&lt;img alt="../forum-disclaimer.jpg" class="align-center" src="http://paulolivier.dehaye.org/forum-disclaimer.jpg" style="width: 863.0px; height: 156.0px;"&gt;&lt;p&gt;The Coursera Terms of Service include numerous such disturbing clauses, as detailed in &lt;a class="reference external" href="http://www.craigbutosi.ca/blog/coursera-or-socrates-was-not-a-content-provider-the-university-of-toronto-and-coursera-agreement"&gt;this wonderful post&lt;/a&gt; from August 2012. That post is a &lt;strong&gt;very highly recommended read&lt;/strong&gt;, since it details issues of free speech and academic freedom, a hot button those days. It also includes the following gem:&lt;/p&gt;
&lt;blockquote&gt;
It is crucial that we pay close attention to the fine print, something unfortunately overshadowed by the immediacy and novelty of Web 2.0 solutions and the latest trends in brand management techniques.&lt;/blockquote&gt;
&lt;p&gt;I can only recommend this approach, but it has to be moderated by a quote given earlier in the piece:&lt;/p&gt;
&lt;blockquote&gt;
Because Coursera mediates between instructor/university and user/student communication, we are dealing with at least four major relationships: user-Coursera, Coursera-instructor/university, user-Coursera-instructor/university, and vice versa. I am mainly focusing on the user-Coursera relation (terms of use and privacy policy), but it should be noted that these are really only separable at the analytical level. In reality, all of these relations are in play at any given time.&lt;/blockquote&gt;
&lt;p&gt;This leaves many unanswered questions, which are not easy to address. It requires access to other contracts, between the instructor, the university and Coursera itself.&lt;/p&gt;
&lt;p&gt;Only one such contract between a university and Coursera has been discussed on a wide scale, the contract given to the University of Michigan. It was the object of a 2012 Chronicle of Higher Education article (an antiquity in the domain of MOOCs), and is based on a Freedom of Information request for the &lt;a class="reference external" href="http://chronicle.com/article/Document-Examine-the-U-of/133063/"&gt;University of Michigan contracts&lt;/a&gt;.
More recently, the UCSC Faculty Union has entered negociations with Coursera, that are &lt;a class="reference external" href="http://ucscfa.org/2013/06/scfas-ongoing-discussion-concerning-ucscs-contract-with-coursera/"&gt;detailed on its blog&lt;/a&gt;. From the outside, these negociations seem very one-sided and highlight differences with the University of Michigan contract:&lt;/p&gt;
&lt;blockquote&gt;
In the Michigan contract, the instructor grants to COURSERA various rights FOR THE DURATION SUCH CONTENT IS OFFERED THROUGH THE PLATFORM (i.e., very limited transfer  of rights).  In our contract, in contrast, the rights are granted TO THE UNIVERSITY and this appears to be irrevocable and not connected to the hosting of the course on the Coursera  platform.&lt;/blockquote&gt;
&lt;p&gt;In other words, the balance of the Coursera contract shifts towards the instructor at the University of Michigan, compared to at UCSC. In the latest Shangai rankings (for the little they are worth), Michigan was ranked 22nd while UCSC was 93rd. Bear in mind that Michigan joined earlier, which might also affect this complex bargaining equation.&lt;/p&gt;
&lt;p&gt;A few other contracts have been put online, intentionally or not, and can be found by googling titles etc. I found eight in total, which can serve as evidence of subtle shifts of the Coursera strategy, and also segmentation according to the characteristics of the universities involved (European vs. American, public vs. private, etc). Since many of those contracts are locked under Non Disclosure Agreements, and this has already become a union issue elsewhere, I can only encourage other academics to push for openness of those contracts at their own institutions.&lt;/p&gt;
&lt;p&gt;(For a cool application of machine learning to the process of teaching, look also at the video around the 4:30 mark. Google seems to focus there on content rather than users, and to extract values from the student contributions rather than their private data. They effectively intend to crowdsource smarter compilers.)&lt;/p&gt;
&lt;p&gt;(I want to thank Ignacio Despujol Zabala for letting me know about this Google I/O session.)&lt;/p&gt;</description><category>coursera</category><category>edtech</category><category>google</category><category>privacy</category><guid>http://paulolivier.dehaye.org/posts/edtech-policies-part-i.html</guid><pubDate>Tue, 09 Sep 2014 10:23:58 GMT</pubDate></item></channel></rss>