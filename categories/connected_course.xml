<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>paulolivier.dehaye.org (connected_course)</title><link>http://paulolivier.dehaye.org/</link><description></description><language>en</language><lastBuildDate>Thu, 11 Sep 2014 18:14:35 GMT</lastBuildDate><generator>http://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Learning, working and ?</title><link>http://paulolivier.dehaye.org/posts/learning-working-and.html</link><dc:creator>Paul-Olivier Dehaye</dc:creator><description>&lt;p&gt;A lot of my recent thoughts have turned around issues of crowdsourcing and online education.&lt;/p&gt;
&lt;img alt="../worklearn.jpg" class="align-right" src="http://paulolivier.dehaye.org/worklearn.jpg" style="width: 346.4px; height: 85.6px;"&gt;&lt;p&gt;One of my co-authors (&lt;a class="reference external" href="http://hci.uni-hannover.de/people/markus"&gt;Markus Krause&lt;/a&gt;) is co-organising a workshop on that topic, &lt;a class="reference external" href="http://www.worklearn.org/"&gt;WorkLearn 2014&lt;/a&gt;. It will take place in Pittsburgh November 2-4, as part of the &lt;a class="reference external" href="http://www.humancomputation.com/2014/"&gt;Human Computation conference HCOMP2014&lt;/a&gt;. Human Computation is another expression interchangeable for &lt;a class="reference external" href="http://paulolivier.dehaye.org/posts/social-teaching-machines.html"&gt;social machine&lt;/a&gt;, although it has different connotations.&lt;/p&gt;
&lt;p&gt;The stated motivation of the workshop is very ambitious:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The online education and crowdsourcing communities are addressing similar problems in educating, motivating and evaluating students and workers. The online learning community succeeds in increasing the supply side of the cognitively skilled labor market, and the crowdsourcing at scale community creates a larger marketplace for cognitively skilled work.&lt;/p&gt;
&lt;p&gt;Linking online platforms for crowd work with platforms for MOOCs has the potential to: provide knowledge and training at a massive scale to contributors; collect data that identify expert skills; engage contributors in simultaneously working and learning in a social environment; and organize large communities around online courses on specific topics. These all provide new opportunities to support and deploy sophisticated algorithms for crowd learning and work.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The most successful example in this direction is of course &lt;a class="reference external" href="http://duolingo.com"&gt;Duolingo&lt;/a&gt;, which helps translate the web while using volunteer labor by language learners. If one omits the learning, the strategy there is not that different from the strategy used by my Coursera coworker &lt;a class="reference external" href="https://www.coursera.org/instructor/bernstein"&gt;Abraham Bernstein&lt;/a&gt; to translate books using &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Amazon_Mechanical_Turk"&gt;Amazon Mechanical Turk&lt;/a&gt;, and indeed part of his efforts aim to design effective tools to program those social machines (with the programming language CrowdLang).&lt;/p&gt;
&lt;embed&gt;&lt;iframe width="640" height="360" src="//www.youtube.com/embed/emCABRV2cUA" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/embed&gt;&lt;p&gt;I have always had some qualms about the &lt;a class="reference external" href="http://florianschmidt.co/the-good-the-bad-and-the-ugly/"&gt;ethics of crowdsourcing&lt;/a&gt;, even though it can clearly be used for good: the prototypical success story is in the work of Ushahidi during the &lt;a class="reference external" href="http://www.ushahidi.com/blog/2012/01/12/haiti-and-the-power-of-crowdsourcing/"&gt;2010 Haiti earthquake&lt;/a&gt;. I was thus very happy to see over Labor Day 2014 that Michael Bernstein from Stanford announced &lt;a class="reference external" href="http://crowdresearch.org/blog/?p=9039"&gt;guidelines for academic requesters on Amazon Mechanical Turk&lt;/a&gt;. He explains the rationale for this (a Turker is a worker on a crowdsourcing platform):&lt;/p&gt;
&lt;blockquote&gt;
An IRB-approved researcher experimented on the [crowdsourcing] platform unannounced. The result was Turker confusion, strife, and wasted time, in a system where time is what it takes to make ends meet.&lt;/blockquote&gt;
&lt;p&gt;These guidelines were themselves crowdsourced, designed together with the Turkers (it's only natural!).&lt;/p&gt;
&lt;p&gt;At the same time, over the summer, there was a huge controversy over the iffy ethics of social platforms experimentation. This is due to the release at the very end of June 2014 of a &lt;a class="reference external" href="http://www.forbes.com/sites/kashmirhill/2014/06/29/facebook-doesnt-understand-the-fuss-about-its-emotion-manipulation-study/"&gt;Facebook experiment on its users&lt;/a&gt; (don't miss the Cornell IRB flowchart there). There are a ton of links about this, but the best is probably the account by Mary L. Gray of an &lt;a class="reference external" href="http://marylgray.org/?page_id=203"&gt;ethics panel that took place at the Microsoft Research Faculty Summit&lt;/a&gt; (and unfortunately was published with much delay).&lt;/p&gt;
&lt;p&gt;In any case, this should give serious pause to any educator. One can see lots of fields suddenly getting much too close, with very different or inexistent values. Online learners, just as Turkers, are vulnerable. &lt;a class="reference external" href="http://nogoodreason.typepad.co.uk/no_good_reason/2014/06/the-ethics-of-digital-scholarship.html"&gt;Martin Weller&lt;/a&gt; and &lt;a class="reference external" href="http://www.elearnspace.org/blog/2014/01/13/the-vulnerability-of-learning/"&gt;George Siemens&lt;/a&gt; have recently insisted on this.&lt;/p&gt;
&lt;p&gt;So, what do you think? Anyone wants to submit a position paper (2 pages) on the topic? Any of my co-learners in MOOCs would like to see what we can do? We could, well... crowdsource it...&lt;/p&gt;
&lt;p&gt;(of course, this was due yesterday: official deadline is "September")&lt;/p&gt;</description><category>connected_course</category><category>coursera</category><category>crowdsourcing</category><category>duolingo</category><category>ethics</category><category>t509massive</category><category>whyopen</category><guid>http://paulolivier.dehaye.org/posts/learning-working-and.html</guid><pubDate>Thu, 11 Sep 2014 00:17:10 GMT</pubDate></item><item><title>Click here so I can tell you about privacy (and invade yours too)</title><link>http://paulolivier.dehaye.org/posts/click-here-so-i-can-teach-you-about-privacy-and-invade-it-too.html</link><dc:creator>Paul-Olivier Dehaye</dc:creator><description>&lt;p&gt;Simply by looking at this page, you agree to this site's privacy policy, which is a copy of the Swiss Railway's statement on the use of Google Analytics:&lt;/p&gt;
&lt;blockquote class="epigraph"&gt;
&lt;p&gt;“This website uses Google Analytics, a web analytics service provided by Google, Inc. (“Google”). Google Analytics uses “cookies”, which are text files placed on your computer, to help the website analyze how users use the site. The information generated by the cookie about your use of the website (including your IP address) will be transmitted to and stored by Google on servers in the United States . Google will use this information for the purpose of evaluating your use of the website, compiling reports on website activity for website operators and providing other services relating to website activity and internet usage. Google may also transfer this information to third parties where required to do so by law, or where such third parties process the information on Google's behalf. Google will not associate your IP address with any other data held by Google. You may refuse the use of cookies by selecting the appropriate settings on your browser, however please note that if you do this you may not be able to use the full functionality of this website. By using this website, you consent to the processing of data about you by Google in the manner and for the purposes set out above.”&lt;/p&gt;
&lt;p class="attribution"&gt;—&lt;a class="reference external" href="https://support.google.com/analytics/answer/6004245"&gt;Google Analytics Terms of Service&lt;/a&gt;, as on the &lt;a class="reference external" href="http://www.sbb.ch/en/meta/data-protection/data-protection-google-analytics-statement.html"&gt;SBB website&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The site itself does not collect data. However I do use Google Analytics, which requires me to introduce this policy as part of the service. The service allows me to track users on this website in various ways, and produces beautiful graphics like this one:&lt;/p&gt;
&lt;img alt="../google-analytics.jpg" class="align-center" src="http://paulolivier.dehaye.org/google-analytics.jpg" style="width: 1020.0px; height: 518.0px;"&gt;&lt;p&gt;The comments below are bound by the Disqus Terms of Service, which are &lt;a class="reference external" href="https://help.disqus.com/customer/portal/articles/466259-privacy-policy"&gt;available here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you don't like it, you can leave. So is the law of the internet.&lt;/p&gt;</description><category>connected_course</category><category>edtech</category><category>privacy</category><category>switzerland</category><guid>http://paulolivier.dehaye.org/posts/click-here-so-i-can-teach-you-about-privacy-and-invade-it-too.html</guid><pubDate>Wed, 10 Sep 2014 06:44:21 GMT</pubDate></item><item><title>(Social) teaching machines</title><link>http://paulolivier.dehaye.org/posts/social-teaching-machines.html</link><dc:creator>Paul-Olivier Dehaye</dc:creator><description>&lt;p&gt;I want to take the opportunity of the recent talk by Audrey Watters on &lt;a class="reference external" href="http://hackeducation.com/2014/09/03/monsters-altc2014/"&gt;Ed-Tech's Monsters&lt;/a&gt; to share some of my thoughts.&lt;/p&gt;
&lt;p&gt;In her talk, Watters physically bases herself at Bletchley Park, a place of invention, ingenuity and deceit that greatly contributed to the Allies' war effort and incidentally the evolution of computing. She then steps back in time to Ludd and his followers, who rebelled against the introduction of machinery in their work. She then segways into the Frankenstein story of a creation abandoned by its master and finally draws parallels with the situation in ed tech today and the "promises" of teaching machines. This was an impossibly bad and short summary of a very good talk, so I would highly recommend to any reader lost here to go read the original. After doing that, please come back.&lt;/p&gt;
&lt;iframe width="900" height="600" src="//www.youtube.com/embed/6qwZm56UadE?rel=0&amp;amp;hd=1&amp;amp;wmode=transparent"&gt;&lt;/iframe&gt;&lt;p&gt;During World War II, cryptographers worked at Bletchley Park to decipher German and Japanese secret messages. These were encoded by various versions of a machine called &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Enigma_machine"&gt;Enigma&lt;/a&gt;, a typewriter wired with multiple electrical contacts that constantly shuffled letters around. It is really a quite dumb but very messy and obfuscated process, with one useful property: at any stage it created an &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Involution_(mathematics)"&gt;involution&lt;/a&gt;, so one can use the same machine to both encrypt and decrypt. You can see little Millie demonstrating this in the video above (shot in September 2013 by yours truly).&lt;/p&gt;
&lt;img alt="../bombe-front.jpg" class="align-right" src="http://paulolivier.dehaye.org/bombe-front.jpg" style="width: 365.04px; height: 273.6px;"&gt;&lt;p&gt;To attack the ciphered messages, the cryptologists at Bletchley Park did not build full on computers, but instead  machines that could simulate many Enigmas in parallel (36 Enigmas per &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Bombe"&gt;Turing Bombe&lt;/a&gt;). These also had extra wiring which encoded additional properties of the Enigma protocol. On any given day, around 200 of these machines were used to recover the common settings for all the encrypted messages sent that day.&lt;/p&gt;
&lt;p&gt;What has always fascinated me with Blecthley Park is the &lt;strong&gt;subtle interplay between humans and the machines&lt;/strong&gt;. While the heavy computations were done by those Bombes, the British did not seek/manage to automate everything. Some steps were always left to manual labor, most notably message passing and picking the initial input. The initial input was known as a &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Cryptanalysis_of_the_Enigma#Crib-based_decryption"&gt;crib&lt;/a&gt;, and  is essentially an informed guess at partial plain text. It seems to have always been more of an art than a science to obtain, even involving some psychology to know where to look. By message passing, I mean that Bletchley Park was not just a bunch of machines: these were disconnected, so there had to actually be many people transcribing output from one machine, making relatively simple decisions (all lights lit!) and entering that output into the next machine. There were several good reasons to do it this way. It is easier to train staff than build a new and complex sorting machine. On top, war is messy, and the Germans changed their procedures several times, requiring agility in the workflow (the Germans were less likely to change their hardware). Over the course of the war, there was constant prototyping of different workflows around core mechanical infrastructure, and this experience helped abstract the generic modern computer (formally, a &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Turing_machine"&gt;Turing Machine&lt;/a&gt;) and eventually build it (unlike Charles Babbage's machine and Ada Lovelace's programs which remained theoretical).&lt;/p&gt;
&lt;blockquote&gt;
The lesson of Bletchley Park is that it is sometimes easier but sufficient to build a social machine rather than a fully automated machine.&lt;/blockquote&gt;
&lt;p&gt;A &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Social_machine"&gt;social machine&lt;/a&gt; is an environment comprising humans and technology interacting and producing outputs or action which would not be possible without both parties present. The term became popular thanks to Tim Berners-Lee, who anticipated them along with the World Wide Web.&lt;/p&gt;
&lt;img alt="../bombe-back.jpg" class="align-left" src="http://paulolivier.dehaye.org/bombe-back.jpg" style="width: 365.04px; height: 273.6px;"&gt;&lt;p&gt;Facebook, for instance, serves as a social machine in multiple ways. You can pass on content to your friends, which they can "like" and comment on, they can tag you in pictures, etc. Every such action is logged, and this machine has a unique goal: to know you better and serve you more valuable ads. All the necessary information has to be volunteered by humans because machines would not have been able to guess it on their own. Sometimes this social machine actively uses your friends to disclose information you might have wanted to keep private, &lt;a class="reference external" href="http://www.digitaltrends.com/social-media/what-exactly-is-a-facebook-shadow-profile/#!bP6C2L"&gt;even if you are not a Facebook user!&lt;/a&gt; Kids ratting on their parents, in other words.&lt;/p&gt;
&lt;p&gt;How is this relevant to ed tech? One of the most successful social machines in education is &lt;a class="reference external" href="http://duolingo.com"&gt;Duolingo&lt;/a&gt;. While it offers students the option of learning a language, it is really built with the intention of translating the web, and uses a creative setup to find and motivate participants. Even the course creation is now crowdsourced, via its &lt;a class="reference external" href="http://incubator.duolingo.com/"&gt;incubator&lt;/a&gt;. MOOCs actually tend to rely heavily on the same type of crowdsourcing. Course creation is crowdsourced to &lt;strong&gt;professors, who can create custom social machines tailored to the topic at hand&lt;/strong&gt;. When the course is run, this machine collects information about who is a good student, who is bad, who is a deep thinker, who is meticulous, who defines their own path, etc. Eventually, the goal might be to evaluate all these characteristics at scale algorithmically (despite all the risks for algorithmic bias that this entails), but the key point is that it can be "faked" at first: via peer feedback and rubric grading, one can use power relationships to inject fairly complicated judgements into this machine, at scale, with little cost.&lt;/p&gt;
&lt;p&gt;Similarly, other relatively complex MOOC services are also sometimes crowdsourced, such as translating course materials, or mutual technical support for the professors and students. One can expect that some of these tasks will eventually also be automated: for instance, some MOOC platforms already use intelligent agents (robots masquerading as humans) to answer student questions in the forums.&lt;/p&gt;
&lt;blockquote&gt;
MOOC platforms offer the option to professors to easily stand up their own social machines. What should be their purpose? Who should be responsible for them?&lt;/blockquote&gt;
&lt;p&gt;Watters insist that Luddites were not rejecting technology, but rather rejecting exploitation. Crowdsourcing already carries significant risks of exploitation, particularly in the &lt;a class="reference external" href="http://florianschmidt.co/the-good-the-bad-and-the-ugly/"&gt;domain of intellectual property&lt;/a&gt;, but this is not the only one. In another talk, she says that &lt;a class="reference external" href="http://hackeducation.com/2013/10/17/student-data-is-the-new-oil/"&gt;"Student data is the new oil"&lt;/a&gt;. Indeed, this seems to be another path that all the big MOOC providers have chosen so far. A professor building a MOOC only helps the platform collect more private information about its users, maybe even under the guise of improving their user experience. But for what purpose exactly? Which engine is running off this oil? Where is it headed? Is this data helping for research in education? In social science? In human-computer interaction? Or simply for profit, selling that data to the highest bidder/best revenue model, without moral guidance? All these options are actively pursued right now, sometimes simultaneously, and professors preparing a MOOC should give great pause to these issues and think carefully at the setting where they have decided to do so. Possibly they might have to fight for the luxury of picking this setting. Professors have a lot of moral responsibility towards the students (the weakest cogs by far in this social machine), to make sure that the free-education-for-all mantra does not turn into another form of exploitation. Do these professors even fully understand the situation? Do they fully understand how &lt;a class="reference external" href="https://www.youtube.com/watch?v=ldhHkVjLe7A"&gt;free-is-a-lie&lt;/a&gt;? Who carries the responsibility of informing them?&lt;/p&gt;
&lt;blockquote class="epigraph"&gt;
&lt;p&gt;Research conducted without applied ethics is morally bankrupt because when scientists lack morals, outside sources can more easily manipulate their work for destructive purposes. In such situations, scientists are likely to adopt the rationalizations of that party to justify their efforts.&lt;/p&gt;
&lt;p class="attribution"&gt;—&lt;a class="reference external" href="http://ashbrook.org/publications/respub-v8n1-cook/"&gt;Erica Cook&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In the Bletchley Park analogy, this moral responsibility is eclipsed by the dramatic circumstances of war. One person encodes, the other one decodes, some people die, some survive but at least it feels fair (to me at least, maybe blinded by my mathematicians' background). Yet the parallels outlined above remain as strong with Los Alamos and the atomic bomb, where Feynman was reorganising his own social machine to &lt;a class="reference external" href="http://youtu.be/0ogSC6JKkrY?t=47m50s"&gt;perform simulations of atomic explosions&lt;/a&gt;, even holding competitions pitting his chimeric machine against actual IBM computers. Certainly, the ethical questions are more nagging with Los Alamos, but on either side of the Atlantic the machine operators never had the opportunity to raise concerns with what they were contributing to. In an environment full of (male) generals and (male) scientists the machines were mostly &lt;a class="reference external" href="http://www.mkheritage.co.uk/bpt/Women/wrensOS.html"&gt;"manned" by women&lt;/a&gt;, within a society that didn't even pretend to give them an equal voice. After the war, many ethical question &lt;a class="reference external" href="http://ashbrook.org/publications/respub-v8n1-cook/"&gt;hung squarely  and solely on the scientists' shoulders&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So if we don't like the current MOOC models, what should be the way forward?&lt;/p&gt;
&lt;blockquote&gt;
Luddites were seeking to disrupt the technological disruption, and we as professors should seek to do the same.&lt;/blockquote&gt;
&lt;p&gt;In fact, one might argue this is part of our job, to help society move forward without fear of a challenge, criticism or controversy, as long as we can back our arguments with evidence. In today's conversation, business logic has misappropriated the words &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Clayton_M._Christensen"&gt;"disruption" and "innovation"&lt;/a&gt; and mostly tied them with technology. In fact, disruption is to be found anywhere in academia, if not more in the humanities: "why?" is a more powerful question than "how?". Certainly some MOOC providers have opened themselves up to this disruption themselves, through &lt;a class="reference external" href="https://www.youtube.com/watch?v=ODL-owGjti8"&gt;overinflated claims of fixing with old technology something that was not necessarily broken&lt;/a&gt;. MOOCs are a fantastic opportunity to build truly new ways of learning, collaborating, discovering and generally helping society progress through exchange of information.&lt;/p&gt;
&lt;p&gt;Getting these improved MOOCs off the ground will be hard. It will require dedication, transparency, freedom to tinker, accountability and tolerance for failure. Above all, it will require rock solid ethical ground, which is too easy to compromise in a competitive environment mixing academia and its "strategic relationships".&lt;/p&gt;</description><category>connected_course</category><category>crypto</category><category>edtech</category><category>social_machine</category><guid>http://paulolivier.dehaye.org/posts/social-teaching-machines.html</guid><pubDate>Thu, 04 Sep 2014 00:46:03 GMT</pubDate></item><item><title>Connected Course: Introduction</title><link>http://paulolivier.dehaye.org/posts/connected-course-introduction.html</link><dc:creator>Paul-Olivier Dehaye</dc:creator><description>&lt;p&gt;This is an introductory post for the connected course taking place at &lt;a class="reference external" href="http://connectedcourses.net"&gt;connectedcourses.net&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My name is Paul-Olivier Dehaye, I am a research mathematician in Zurich. I have taught for close to 15 years at university level, and two years ago started investing time in online education. Last year I taught a &lt;cite&gt;Programming in python&lt;/cite&gt; SPOC and &lt;a class="reference external" href="https://www.coursera.org/course/massiveteaching"&gt;Teaching goes massive: New skills required&lt;/a&gt; on Coursera, as well as supervising several edtech projects with students. I am rerunning the python SPOC in the Fall 2014.&lt;/p&gt;
&lt;p&gt;This course seems to match my interests very closely, and I am looking forward to relating the themes explored in the course with my own experiences in higher education. I am hoping to learn a lot, contribute positively to the discussion, and maybe get some peer feedback. Of particular resonance to me are issues of silos, faculty autonomy and independence, vulnerability (of students and instructor), censorship, data privacy, ethics and co-discovery (in addition to co-learning).&lt;/p&gt;
&lt;p&gt;I am also interested in the community of this course itself: are there marked differences between STEM and other fields? How to make STEM higher ed professors at research institutions understand the importance of those issues? How to communicate that bad decisions now could significantly affect the future of their profession?&lt;/p&gt;
&lt;p&gt;Due to personal reasons, I am not entirely sure of how sustained my effort in the course will be, but will do my best!&lt;/p&gt;
&lt;p&gt;I am participating in this course as an individual, a student seeking to learn more, and not acting as a representative of my employer. Undoubtedly though what I learn here I will seek to reapply in my professional life.
Should you have any question about my motivation in participating in this course, please ask me below or in private. Thanks!&lt;/p&gt;</description><category>connected_course</category><guid>http://paulolivier.dehaye.org/posts/connected-course-introduction.html</guid><pubDate>Fri, 29 Aug 2014 10:59:27 GMT</pubDate></item></channel></rss>